{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Financial Networks\n",
    "\n",
    "## Introduction\n",
    "\n",
    "- Activity in the stock markets, has <u>always attracted a great deal of interest from not only investors,but also scientists</u>. $\\rightarrow$ Have wanted to discover regularity in price fluctuations.\n",
    "- <u>Continuous storage of a variety of data</u> i.e. numbers of transactions, pricing, numbers of bids and asks for all traded stocks worldwide <u>constantly produces one of the largest datasets available to researchers</u>.\n",
    "- This discipline has attracted over time the interest of investors convinced that it would in principle be possible to <u>predict the future behaviour by inspecting the past history</u>.\n",
    "- It is noteworthy that since <u>the market is not totally isolated</u>, if many believe that the price will go up, then the price will effectively go up (self-fulfilling prophecy). $\\rightarrow$ This creates an interesting feedback between observer and system observed.\n",
    "\n",
    "\n",
    "- The study of time series is just one of the ways in which we can study quantitatively economic and financial networks.\n",
    "- Another approach that is particularly fruitful is to describe the various connections between financial institutions in the form of a network.\n",
    "- The structure obtained is particularly complex,since an edge (or various kinds of edges) can represent lending,exposure,insurance,credit default swaps (CDS),own- ership, interlock in the board etc.\n",
    "\n",
    "\n",
    "- The aim of this chapter is to <mark>provide the reader with the main quantitative instruments to describe these systems</mark>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from Yahoo! Finance\n",
    "- <u>Financial data are very difficult to collect</u>, essentially due to disclosure problems,but also because of the absence of specific policy regulations on certain kinds of transactions; also most of the data are not available in an aggregated form.\n",
    "- <u>After the financial crisis</u> which started with sub-prime mortgages in 2008, it became clear to a variety of policy regulators and control organisations,that the complexity of the financial structure and our poor knowledge of it had been one of the causes of the turndown in the economy.\n",
    "- From that moment a series of international organisations and companies <u>started collecting and making available various data</u>, unfortunately not always accessible to scientists.\n",
    "- The set of data we present here <u>has been downloaded from the Yahoo! Finance web service</u>, which offers daily historical data for the closure prices of stock traded in various markets.\n",
    "- Present <mark>how to interact with the service in order to get the relevant data we need to explore the correlations between stocks for companies present in the NYSE (New York Stock Exchange) index</mark>.\n",
    "- The historical data from Yahoo! Finance presents information about <u>the volume of stocks transacted, the highest, the lowest, the opening, and the closing values, as well as an adjusted closing value</u> that provides the closing price (on the requested day,week, or month for any stock) adjusted for all applicable splits and dividend distributions.\n",
    "\n",
    "- <code>$ pip install yahoo_finance</code>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "# Connecting with the Yahoo! Finance service\n",
    "\n",
    "import yahoo_finance as yf\n",
    "\n",
    "yahoo = yf.Share('YHOO')\n",
    "d = yahoo.get_historical('2014-05-19', '2014-05-20')\n",
    "print(\"A week of stock daily quotations:\")\n",
    "for e in d:\n",
    "    print(e)\n",
    "print(\"Info about the company:\", yahoo.get_info())\n",
    "print(\"Market capitalization in dollars:\", yahoo.get_market_cap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The historical data from Yahoo! Finance : <u>volume of stocks transacted, the highest, the lowest, the opening, and the closing values, as well as an adjusted closing value</u> that provides the closing price.\n",
    "\n",
    "- But, [Yahoo financel API discontinued from 15th, May](http://unintelligent-nerd.blogspot.kr/2017/06/yahoo-finance-api-discontinued.html)\n",
    "\n",
    "\n",
    "- [pandas-datareader](https://pandas-datareader.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "- <code>$ pip install pandas-datareader</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime(2014, 5, 19)\n",
    "end = datetime.datetime(2014, 5, 20)\n",
    "\n",
    "d = web.DataReader(\"YHOO\", 'google', start, end)\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "d = yahoo.get_historical('2014-01-01', '2014-12-31')\n",
    "V = []\n",
    "for s in d:\n",
    "    print(s['Date'], float(s['Volume'])*float(s['Close']))\n",
    "    V.append(float(s['Volume'])*float(s['Adj_close']))\n",
    "\n",
    "plot(V)\n",
    "# savefig('yahoo_volumn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = web.DataReader(\"YHOO\", \"google\", \"2014-01-01\", \"2014-12-31\")\n",
    "# print(d['Volume']*d['Close'])\n",
    "plt.plot(d['Close']*d['Volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Company List (NASDAQ, NYSE, & AMEX)](http://www.nasdaq.com/screening/company-list.aspx)\n",
    "    - [Download NYSE](http://www.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nyse&render=download)\n",
    "    \n",
    "    \n",
    "- Only use only companies with a market Cap greater than 50B$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import time\n",
    "\n",
    "with open(\"./data/companylist.csv\", 'r') as f:\n",
    "    cap_threshold = 50.0\n",
    "    list_stocks = []\n",
    "    f.readline()  # skip header\n",
    "    for line in f:\n",
    "        line = line.split(',')\n",
    "        sym = line[0][1:-1]\n",
    "        \n",
    "        share = yf.Share(sym)\n",
    "        y_marketcap = share.get_market_cap)\n",
    "        if not y_market_cap:\n",
    "            continue\n",
    "        \n",
    "        if y_market_cap[-1] == 'B' and float(y_market_cap[:-1]) > cap_threshomd and\n",
    "            line[0].find('^') == -1:\n",
    "            print(sym, y_market_cap)\n",
    "            list_stocks.append((line[0][1:-1], line[1][1:-1], line[5][1:-1], line[6][1:-1]))   \n",
    "        time.sleep()\n",
    "\n",
    "print(list_stocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get stock labels, sectors, and industries\n",
    "\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/companylist.csv\")\n",
    "# df = pd.read_csv(\"./data/companylist-nasdaq.csv\")\n",
    "# print(df.head())\n",
    "print(\"Original # of companies :\", len(df))\n",
    "\n",
    "df = df[df['MarketCap'].str[-1] == 'B']\n",
    "# print(df.head())\n",
    "print(\">B$ market cap company # :\", len(df))\n",
    "\n",
    "df['MarketCap'] = df.MarketCap.apply(lambda x: re.sub(r'^\\$|B$','', x))\n",
    "df = df[df.MarketCap.astype(float) > 50.0]\n",
    "# print(df.head())\n",
    "print(\"Company # of >50B Market Cap :\", len(df))\n",
    "\n",
    "list_stocks = df[['Symbol', 'Name', 'Sector', 'industry']].values.tolist()\n",
    "print(list_stocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby([\"Sector\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "diz_sectors = {}\n",
    "for s in list_stocks:\n",
    "    diz_sectors[s[0]] = s[2]\n",
    "\n",
    "list_ranking = list(Counter(diz_sectors.values()).items())\n",
    "# list_ranking = []\n",
    "# for s in set(diz_sectors.values()):\n",
    "#     print(s,  sum(len(v) for v in diz_sectors.values()))\n",
    "#     print(s, diz_sectors.values(), sum(map(len, diz_sectors.get(s))))\n",
    "#     print(s, sum(len(v) for v in diz_sectors.get(s)))\n",
    "#     list_ranking.append((Counter(diz_sectors.values()), s))\n",
    "    # s가 포함된 diz_sectors을 수를 넣어야 함\n",
    "\n",
    "list_ranking.sort(reverse=True)\n",
    "list_colors=['red', 'green', 'blue', 'black', 'cyan', 'magenta', 'yellow', 'coral', 'aquamarine', 'gray', 'goldenrod', 'palegreen']\n",
    "# list_colors=['0.0', '0.2', '0.4', '0.6', '0.7', '0.8', '0.9']\n",
    "\n",
    "diz_colors = {}\n",
    "\n",
    "for s in list_ranking:\n",
    "    print(\"s\", s)\n",
    "    if s[1] == 'n/a':  # ???\n",
    "#         diz_colors[s[1]] = 'white'\n",
    "        diz_colors[s[0]] = 'white'\n",
    "        continue\n",
    "#     if list_colors == []:\n",
    "    if not list_colors:\n",
    "#         diz_colors[s[1]] = 'white'\n",
    "        diz_colors[s[0]] = 'white'\n",
    "        continue\n",
    "#     diz_colors[s[1]] = list_colors.pop(0)\n",
    "    diz_colors[s[0]] = list_colors.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diz_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prices time series\n",
    "- The time series of a stock price is a typical quantity that investors (right or wrong) use when considering their investments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieving historical data\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from pandas_datareader._utils import RemoteDataError\n",
    "\n",
    "start = datetime.datetime(2013, 5, 1)\n",
    "end = datetime.datetime(2014, 5, 31)\n",
    "# start = datetime.datetime(2016, 5, 1)\n",
    "# end = datetime.datetime(2017, 5, 31)\n",
    "diz_comp = {}\n",
    "for s in list_stocks:\n",
    "#     print(s[0])\n",
    "    try:\n",
    "        diz_comp[s[0]] = web.DataReader(s[0], 'google', start, end)\n",
    "    except RemoteDataError:\n",
    "        print(\"[WARN] No information for '%s'\" % s[0])\n",
    "        continue\n",
    "\n",
    "#create dictionaries of time series for each company\n",
    "diz_historical={}\n",
    "for k in diz_comp.keys():\n",
    "    if k not in diz_comp: \n",
    "        print(k, \"is not in diz_comp\")\n",
    "        continue\n",
    "    ts_list = diz_comp[k].index.tolist()  # a list of Timestamp's\n",
    "    date_list = [ ts.date() for ts in ts_list ]  # a list of datetime.date's\n",
    "    date_str_list = [ str(date) for date in date_list ]  # a list of strings\n",
    "    if not date_str_list:\n",
    "        print(\"[WARN]\", k, \"has no data\")\n",
    "        continue \n",
    "    diz_historical[k] = dict(zip(date_str_list, diz_comp[k].Close.values.tolist()))\n",
    "\n",
    "for k in diz_historical.keys():\n",
    "    print(k, len(diz_historical[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While the link between past and future performance has never been demonstrated, there is nevertheless a certain consensus that “on average\" this information is valuable to the investors.\n",
    "- In particular the <mark>return</mark> and the <mark>volatility</mark> are considered <u>the most important indicators</u>.\n",
    "- Define the proportional return of the investment in the period $\\Delta t$:\n",
    "\n",
    "$$r(\\Delta t)=\\frac{p(t_0+\\Delta t)-p(t_0)}{p(t_0)}$$\n",
    "given interval $\\Delta t$, price at the beginning $p(t_0)$ and at the end $p(t_0+\\Delta t)$\n",
    "\n",
    "- Assumed investment in only a certain number of one type of stock, so that we can use the price to determine costs and gains. The above equation in the limit $(\\Delta t\\rightarrow 0)$ can be written as $r(t)\\simeq\\frac{d\\ln(p(t))}{dt}$.\n",
    "- This expression passing to discrete time steps takes the following form:\n",
    "$$r=\\ln{p(t_0+\\Delta t)}-\\ln{p(t_0)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Return of prices\n",
    "\n",
    "from math import log\n",
    "\n",
    "reference_company = 'ABEV'\n",
    "# reference_company = 'MSFT'\n",
    "diz_returns = {}\n",
    "d = list(diz_historical[reference_company].keys())\n",
    "d.sort()\n",
    "# print(len(d), d)\n",
    "\n",
    "for c in diz_historical.keys():\n",
    "    if len(diz_historical[c].keys()) < len(d):\n",
    "        continue\n",
    "    diz_returns[c] = {}\n",
    "    for i in range(1, len(d)):\n",
    "        diz_returns[c][d[i]] = \\\n",
    "            log(float(diz_historical[c][d[i]])) - log(float(diz_historical[c][d[i-1]]))\n",
    "            \n",
    "# print(diz_returns[reference_company])\n",
    "diz_returns[reference_company]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Among the various definitions of <mark>volatility</mark> $\\sigma$, <u>the simplest is the standard deviation of the value of prices $p(t)$</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic statistics and the correlation coefficient\n",
    "\n",
    "# mean\n",
    "def mean(X):\n",
    "    m = 0.0\n",
    "    for i in X:\n",
    "        m = m + i\n",
    "    return m/len(X)\n",
    "\n",
    "# covariance\n",
    "def covariance(X, Y):\n",
    "    c = 0.0\n",
    "    m_X = mean(X)\n",
    "    m_Y = mean(Y)\n",
    "    for i in range(len(X)):\n",
    "        c = c + (X[i] - m_X) * (Y[i] - m_Y)\n",
    "    return c/len(X)\n",
    "\n",
    "# pearson correlation coefficent\n",
    "def pearson(X, Y):\n",
    "    return covariance(X, Y)/(covariance(X, X)**0.5 * covariance(Y, Y)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Pearson correlation coefficent](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of prices\n",
    "- Correlations in time series (or more simply comovements) are also considered to be extremely valuable.\n",
    "- The idea is that every investor has precise knowledge of the market (highly unrealistic (Greenwald,Bruce and Stiglitz,1993)) and since (s)he is perfectly rational (another strong assumption),(s)he wants to maximise the return and at the same time minimise the risk of their investments.\n",
    "- This is obtained by choosing the proportion of the investments among all the assets present in the market (considered “complete\") and by essentially building a portfolio of all the different assets. - “Theory of portfolio\"(Markowitz, 1952)\n",
    "\n",
    "\n",
    "- If two or more assets have a past history of common behaviour (i.e. they both go up or down at the same time) we can measure a correlation between their price evolution as given by these “comovements\".\n",
    "\n",
    "\n",
    "- The correlation $\\rho_{ij}(\\Delta t)$ between the price returns over a time $\\Delta t$ Correlation is computed by means of\n",
    "$$\\rho_{ij}(\\Delta t)=\\frac{\\langle r_ir_j\\rangle-\\langle r_i\\rangle\\langle r_j\\rangle}{\\sqrt{(\\langle r^2_i\\rangle-\\langle r_i\\rangle^2)(\\langle r^2_j\\rangle-\\langle r_j\\rangle^2)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation of price returns\n",
    "\n",
    "def stocks_corr_coeff(h1, h2):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    intersec_dates = set(h1.keys()).intersection(set(h2.keys()))\n",
    "    for d in intersec_dates:\n",
    "        l1.append(float(h1[d]))\n",
    "        l2.append(float(h2[d]))\n",
    "    return pearson(l1, l2)\n",
    "\n",
    "print(stocks_corr_coeff(diz_returns[reference_company], \n",
    "                        diz_returns[reference_company]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal spanning trees(최소 신장 트리)\n",
    "- Trees are economical graphs in the sense that they connect a fixed number of vertices through the minimal number of edges.\n",
    "- Trees are also often used to investigate network structure,as in the case of the breadth first search algorithms and/or as in this case,to filter the information present in a complete graph.\n",
    "- Trees are perfect for classifying information(e.g., in the case of botany or zoology).\n",
    "\n",
    "\n",
    "- Using the correlation values defined we obtain a set of $n\\times (n - 1)/2$ numbers characterising the similarity of any of the $n$  stocks with respect to all the other $n-1$ stocks.\n",
    "- A metric distance between any pair of stocks by defining\n",
    "$$D_{i,j}(\\Delta t)=\\sqrt{2(1-\\rho_{ij}(\\Delta T))}$$\n",
    "- With this choice, $d_{i,j}(\\Delta t)$ fulfils the three axioms of a metric distance:\n",
    "    - $d_{i,j}(\\Delta t)=0$ iff $i=j$;\n",
    "    - $d_{i,j}(\\Delta t)=d_{j,i}(\\Delta t)\\ \\forall i,j$;\n",
    "    - $d_{i,j}(\\Delta t)\\leq d_{i,j}(\\Delta t)+d_{k,j}(\\Delta t)\\ \\forall i,j,k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Building the network with the metric distance\n",
    "\n",
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "corr_network = nx.Graph()\n",
    "\n",
    "num_companise = len(diz_returns.keys())\n",
    "for i1 in range(num_companise-1):\n",
    "    for i2 in range(i1+1, num_companise):\n",
    "        stock1 = list(diz_returns.keys())[i1]\n",
    "        stock2 = list(diz_returns.keys())[i2]\n",
    "        metric_distance = math.sqrt(2*(1.0 - stocks_corr_coeff(diz_returns[stock1], diz_returns[stock2])))\n",
    "        corr_network.add_edge(stock1, stock2, weight=metric_distance)\n",
    "        \n",
    "print(\"number of nodes:\", corr_network.number_of_nodes())\n",
    "print(\"number of edges:\", corr_network.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The method for constructing the MST linking $N$ objects is known in multivariate analysis as the “nearest neighbour single linkage cluster algorithm\" (Mardia et al., 1979).\n",
    "- The idea is to consider the above-defined distance between two vertices as the weight of the link connecting them. \n",
    "- At this point, we <u>keep only the strongest correlations or the shortest distances</u>. To filter among the $\\simeq n^2$ links we first <u>rank all the edges</u>, then we <u>start from the vertices which are nearest</u> and we <u>keep adding new vertices by following the rank of the edges</u>, <u>discarding all the links that would form a cycle</u> (in this way, by construction, the graph is acyclic, i.e. a tree). \n",
    "- Finally, we <u>stop when all the vertices are drawn</u> (in this way the tree is spanning).\n",
    "- Schematising:\n",
    "    1. rank a couple of vertices (stocks) from the nearest to the farthest \n",
    "    2. draw the first edge from this rank\n",
    "    3. continue in the rank\n",
    "    4. if the new edge does not close a cycle draw it\n",
    "    5. go to point 3\n",
    "    6. stop when all the vertices have been drawn.\n",
    "    \n",
    "- Ref\n",
    "    - http://leeyongjeon.tistory.com/entry/최소신장트리Minimum-Spanning-Trees-크루스칼Kruskal-알고리즘\n",
    "    - [Wikipdia](https://en.wikipedia.org/wiki/Minimum_spanning_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Minimal spanning tree (Prim's algorithm)\n",
    "\n",
    "tree_seed = reference_company\n",
    "N_new = []\n",
    "E_new = []\n",
    "N_new.append(tree_seed)\n",
    "while len(N_new) < corr_network.number_of_nodes():\n",
    "    min_weight = 10000000.0\n",
    "    for n in N_new:\n",
    "        for n_adj in corr_network.neighbors(n):\n",
    "            if not n_adj in N_new:\n",
    "                if corr_network[n][n_adj]['weight'] < min_weight:\n",
    "                    min_weight = corr_network[n][n_adj]['weight']\n",
    "                    min_weight_edge = (n, n_adj)\n",
    "                    n_adj_ext = n_adj\n",
    "    E_new.append(min_weight_edge)\n",
    "    N_new.append(n_adj_ext)\n",
    "    \n",
    "tree_graph = nx.Graph()\n",
    "tree_graph.add_edges_from(E_new)\n",
    "\n",
    "for n in tree_graph.nodes():\n",
    "#     print(diz_sectors[n])\n",
    "    tree_graph.node[n]['color'] = diz_colors[diz_sectors[n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Printing the financial minimum spannning tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pos = nx.nx_pydot.graphviz_layout(tree_graph, prog='neato',\n",
    "                                  args='-Gmodel=subset -Gratio=fill')\n",
    "plt.figure(figsize=(20,20))\n",
    "nx.draw_networkx_edges(tree_graph, pos, width=2,\n",
    "                       edge_color='black', alpha=0.5, style='solid')\n",
    "nx.draw_networkx_labels(tree_graph, pos)\n",
    "for n in tree_graph.nodes():\n",
    "    nx.draw_networkx_nodes(tree_graph, pos, [n], node_size=800,\n",
    "                           alpha=0.5, node_color=tree_graph.node[n]['color'],\n",
    "                           with_labels=True)\n",
    "# colors = []\n",
    "# for n in tree_graph.nodes():\n",
    "#     colors.append(tree_graph.node[n]['color'])\n",
    "# nc = nx.draw_networkx_nodes(tree_graph, pos, tree_graph.nodes(), node_size=800,\n",
    "#                        alpha=0.7, node_color=colors,\n",
    "#                        with_labels=True, cmap=plt.cm.Greys_r)\n",
    "\n",
    "plt.legend(diz_colors, markerscale=0.4, loc='lower left')\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
