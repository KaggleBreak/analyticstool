{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\vect}[1]{\\boldsymbol{#1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modelling\n",
    "## Introduction\n",
    "- The application of network theory is really <u>multidisciplinary</u> and faces similar problems across the various topics.\n",
    "- It is always important to be able to reproduce <mark><b>synthetically</b></mark> in a computer the system we are studying.\n",
    "- This is the basis of the art of modelling, which allows various and important applications.\n",
    "\n",
    "\n",
    "- Models\n",
    "    - to predict the outcome of an experiment.\n",
    "    - to understand the basic principles shaping the of a given phenomenon.\n",
    "    - It is always validation with data from experiments that allows us to determine if the model hypothesis is right or not.\n",
    "\n",
    "- The aims of this chapter\n",
    "    - <u>to present the most used models in the fìeld of complex networks</u>,\n",
    "    - to illustrate the basic principles on which they are based (sometimes inspired by similar situations in different fìelds),\n",
    "    - to provide the code for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential growth, chains, and random graph\n",
    "\n",
    "### Static models\n",
    "#### One species: Fibonacci sequence\n",
    "- The simplest assumption of a food web, <u>on a short time scale</u> where mutation does not happen is when we deal with one species and unlimited resources.\n",
    "- This is a <u>highly unlikely assumption</u> both in ecology and in other fields, but it is an example that is important historically and in our opinion pleasant to describe.\n",
    "<img src=\"table6.1.png\" width=320>\n",
    "<center><font size=-1>[counts the pairs of rabbits. The formula is \n",
    "$n(t) = n(t - 1) + n(t - 2)$]</font></center>\n",
    "\n",
    "\n",
    "- As $t\\rightarrow\\infty$  we have that the ratio of two consecutive terms approaches a constant value that is $\\lim_{t\\rightarrow\\infty}n(t) = \\phi n(t - 1)$ (such a value of $\\phi$ becomes more and more similar to the \"golden ratio\", $\\phi^G =\\frac{1+\\sqrt{5}}{2}\\simeq 1.61803\\cdots$, a number particularly used by architects and artists to mimic the beauty of nature).\n",
    "$$\\frac{dn}{dt}=\\frac{n(t+1)-n(t)}{1}\\simeq(\\phi -1)n(t)$$\n",
    "whose solution is $n(t)=n(t_0)e^{(\\phi -1)(t-t_0)}$.\n",
    "- Ref\n",
    "    - [황금비](http://terms.naver.com/entry.nhn?docId=3582431&cid=58714&categoryId=58714)\n",
    "    - [피보나치 수열](http://terms.naver.com/entry.nhn?docId=3338362&cid=47324&categoryId=47324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the Fibonacchi sequence\n",
    "def fibonacci(sequence_length):\n",
    "    sequence = [0, 1]\n",
    "    if sequence_length < 1:\n",
    "        print(\"Fibonacci sequence only defined for length 1 or greater\")\n",
    "        return\n",
    "    if 0 < sequence_length < 3:\n",
    "        return sequence[:sequence_length]\n",
    "    for i in range(2, sequence_length):\n",
    "        sequence.append(sequence[i-1] + sequence[i-2])\n",
    "    return sequence\n",
    "\n",
    "fibonacci(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fib_recursive(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib_recursive(n-1) + fib_recursive(n-2)\n",
    "    \n",
    "print([fib_recursive(i) for i in range(12)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two species: Lotka-Volterra equations\n",
    "- The simplest way to describe a more realistic food web is to introduce at least one prey and one predator.\n",
    "- In the simplest version with one prey and one predator z,we have\n",
    "$$\\begin{cases} \\textbf{y'(t)}=\\alpha\\textbf{y(t)z(t)}-\\beta\\textbf{y(t)}\\\\ \\textbf{z'(t)}=\\gamma\\textbf{z(t)}-\\delta\\textbf{z(t)y(t)} \\end{cases}$$\n",
    "- For the predator $y(t)$:\n",
    "    - the first term $\\alpha y(t)z(t)$ describes the growth based on predation on $z$. It is an exponential growth (the factor $y(t)$, where the resources are proportional to the prey $\\alpha z(t)$;\n",
    "    - the second item $\\beta y(t)$ takes into account death or emigration.\n",
    "- For the prey $z$:\n",
    "    - the first term $\\gamma z(t)$ is an exponential growth (assuming infinite and constant resources)\n",
    "    - the second term $\\delta z(t)y(t)$ accounts for predation from predators. Since not all the losses by $z$ contribute to the growth of $y$, this term is different from the first term in the predator equation.\n",
    "    \n",
    "- Ref\n",
    "    - https://ko.wikipedia.org/wiki/로트카-볼테라_방정식\n",
    "    - https://en.wikipedia.org/wiki/Lotka–Volterra_equations\n",
    "    - http://blog.naver.com/dydrogud22/220483569583"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [SymPy](http://www.sympy.org/en/index.html) : a Python library for symbolic mathematics.\n",
    "- <code>$ pip install sympy</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Solve the Lotka-Volterra differential equations\n",
    "\n",
    "from sympy import *\n",
    "\n",
    "#defining the variables and parameters\n",
    "var('y z')\n",
    "var('alfa beta gamma delta', positive=True)\n",
    "\n",
    "#defining the equations\n",
    "dy = alfa*z*y - beta*y\n",
    "dz = gamma*z - delta*z*y\n",
    "\n",
    "#solving the Lotka Volterra equations\n",
    "(y0, z0), (y1, z1) = solve([dy, dz], (y, z))\n",
    "A = Matrix((dy, dz))\n",
    "print(\"A = \", A, \"\\n\")\n",
    "\n",
    "#computing the Jacobia\n",
    "Jacobian = A.jacobian((y, z))\n",
    "print(\"Jacobian =\", Jacobian)\n",
    "B = Jacobian.subs(y, y0).subs(z, z0)\n",
    "C = Jacobian.subs(y, y1).subs(z, z1)\n",
    "print(\"B = \", B)\n",
    "print(\"C = \", C, \"\\n\")\n",
    "\n",
    "#stability of the fixed points\n",
    "solutionB = B.eigenvals()\n",
    "solutionC = C.eigenvals()\n",
    "print(\"Solution B = \", solutionB)\n",
    "print(\"Solution C = \", solutionC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ref\n",
    "    - https://ko.wikipedia.org/wiki/야코비_행렬\n",
    "    - http://dexterstory.tistory.com/777\n",
    "    - http://scipy-cookbook.readthedocs.io/items/LoktaVolterraTutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many species, random competition\n",
    "- When adding more and more species to the system, the set of relationships can be effectively described by means of a predation matrix $\\vect{A}$ whose entries $a_{ij}$ have the following property\n",
    "$$a_{ij}=\\begin{cases} 1 & \\text{if $j$ predates $i$}\\\\ 0 & \\text{otherwise ($j$ doese not predate $i$)} \\end{cases}$$\n",
    "- That is $\\vect{A}$ is the matrix of an oriented graph where the <u>out-degree gives the number of predators</u> (the arrows indicate the flow of nutrients). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random graphs\n",
    "- Random graphs (Erdös and Rényi,1959) represent the benchmark for any real network.\n",
    "- In a random graph, once given the number of vertices and the probability $p$ to draw an edge between a couple of them, we obtain a graph where connections are assigned randomly.\n",
    "$$P_k=\\frac{(n-1)!}{(n-1-k)!k!}p^k(1-p)^{n-1-k}=\\left(\\matrix{n-1 \\cr k}\\right) p^k(1-p)^{n-1-k}$$\n",
    "\n",
    "- That is, we find a binomial distribution for the various values of degree k; note that the distribution is automatically normalised since\n",
    "$$\\sum_{k=1,n-1}P_k = (p+(1-p))^{n-1}=1$$\n",
    "- A huge amount of analytical work has been done with random graphs (Bollobás,1979; Bollobás,1985) and those analytical results constitute the <u>basic benchmark to evaluate the behaviour of any other graph</u>.\n",
    "- Ref\n",
    "    - https://en.wikipedia.org/wiki/Random_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generating Random Networks (Erdös-Rényi)\n",
    "\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "Number_of_nodes = 10\n",
    "p = 0.4\n",
    "\n",
    "G = nx.Graph()\n",
    "for n in range(Number_of_nodes):\n",
    "    G.add_node(n)\n",
    "    \n",
    "node_list = G.nodes()\n",
    "\n",
    "for i1 in range(len(node_list)-1):\n",
    "    for i2 in range(i1+1, len(node_list)):\n",
    "        if random.random() < p:\n",
    "            G.add_edge(node_list[i1], node_list[i2])\n",
    "\n",
    "pos = nx.circular_layout(G)\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By above approach allows us to reproduce a variety of different behaviours, but does not necessarily allow us to reproduce the real complexity of a graph, with correlation between vertices made evident by non-trivial values of assortativity and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating Random Networks (Erdös-Rényi)\n",
    "# Modified by etc(2017/07/20)\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "Number_of_nodes = 10\n",
    "p = 0.4\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.ion()\n",
    "\n",
    "G = nx.Graph()\n",
    "for n in range(Number_of_nodes):\n",
    "    G.add_node(n)\n",
    "    \n",
    "node_list = G.nodes()\n",
    "\n",
    "for i1 in range(len(node_list)-1):\n",
    "    for i2 in range(i1+1, len(node_list)):\n",
    "        rn = random.random()\n",
    "        if rn < p:\n",
    "            pos = nx.circular_layout(G)\n",
    "            plt.axis('off')\n",
    "            nx.draw_networkx_nodes(G, pos, with_labels=True)\n",
    "            G.add_edge(node_list[i1], node_list[i2])\n",
    "            plt.pause(0.2)\n",
    "            nx.draw_networkx_edges(G, pos, with_labels=True)\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            plt.pause(0.2)\n",
    "\n",
    "# nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomising a graph\n",
    "- Real networks display a long-range level of correlation.\n",
    "- Not only is the degree <u>distribution scale-free</u>, but also <u>higher-order correlations</u> are present. It is then useful to have a method of characterising how much these correlations count with respect to a null case.\n",
    "- This means that we would like to measure the properties of a real graph against another one where correlations are not present.\n",
    "- This can be done by realising a randomisation of the initial graph, not at the level of the degree (a random graph with the same number of vertices and edges of a real network is very likely not to have the same degree sequence), but at a higher level.\n",
    "\n",
    "\n",
    "- A procedure to destroy correlation by preserving degree sequence can easily be outlined as follows (Maslov et al. , 2004).\n",
    "- Extract one couple of edges (A, B) and (C, D) with four different vertices (A, B, C, D) and swap the extremes (end vertices) ofthe two edges (i.e. (A-B), (C-D) → (C-B) , (A-D)) as outlined in figure below.\n",
    "\n",
    "\n",
    "<img src=\"Fig6.1.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomising graphs\n",
    "\n",
    "number_of_swaps = 2\n",
    "\n",
    "while number_of_swaps > 0:\n",
    "    # pick at random a couple of edges they don’t share nodes\n",
    "    edges_to_swap = random.sample(G.edges(), 2)\n",
    "    e0 = edges_to_swap[0]\n",
    "    e1 = edges_to_swap[1]\n",
    "    \n",
    "    if len(set([e0[0], e0[1], e1[0], e1[1]])) < 4:\n",
    "        continue\n",
    "    \n",
    "    # check if the edge already exists and eventually add it\n",
    "    if not G.has_edge(e0[0], e1[1]):\n",
    "        G.add_edge(e0[0], e1[1])\n",
    "    G.remove_edge(e0[0], e0[1])\n",
    "    if not G.has_edge(e0[1], e1[0]):\n",
    "        G.add_edge(e0[1], e1[0])\n",
    "    G.remove_edge(e1[0], e1[1])\n",
    "    number_of_swaps -= 1\n",
    "\n",
    "pos = nx.circular_layout(G)\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration models\n",
    "- The importance of random graphs is due to the fact that they represent an instance of being a graph when no particular correlation in the vertices is present.\n",
    "- Build a a graph starting from the basic constituents, the vertices with their given edge stubs.\n",
    "<img src=\"Fig6.2.png\" width=400>\n",
    "1. order the vertices from the one with the largest degree to that with the smallest;\n",
    "2. assign to any of them a number of edge stubs given by the degree sequence;\n",
    "3. write down an array whose entries are all t he stubs indicated by the label of the\n",
    "vertex to which they belong;\n",
    "4. scramble t he array exchanging the position of the entries;\n",
    "5. take the entries in block for two and draw an edge between the vertices indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Configuration model\n",
    "\n",
    "degree_sequence = [6, 4, 3, 2, 1, 1, 1]\n",
    "\n",
    "# this generate the list of uppercast chars as labels for the nodes\n",
    "uppercase_char_list = [chr(i) for i in range(65, 91)]\n",
    "\n",
    "degree_sequence.sort(reverse=True)\n",
    "print(\"degree sequence:\", degree_sequence)\n",
    "\n",
    "stub_list = []\n",
    "\n",
    "for deg in degree_sequence:\n",
    "    label = uppercase_char_list.pop(0)\n",
    "    for stub in range(deg):\n",
    "        stub_list.append(label)\n",
    "        \n",
    "print(\"ordered stub labels\", stub_list)\n",
    "\n",
    "random.shuffle(stub_list)\n",
    "\n",
    "print(\"shuffled stub labels\", stub_list)\n",
    "\n",
    "MG = nx.MultiGraph()\n",
    "\n",
    "while stub_list != []:\n",
    "# while stub_list:\n",
    "    node1 = stub_list.pop(0)\n",
    "    node2 = stub_list.pop(0)\n",
    "    MG.add_edge(node1, node2)\n",
    "    \n",
    "print(\"graph edge list:\", MG.edges())\n",
    "\n",
    "pos = nx.circular_layout(MG)\n",
    "nx.draw(MG, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph edge list: [('B', 'A'), ('B', 'G'), ('B', 'C'), ('B', 'D'), ('F', 'C'), ('D', 'A'), ('E', 'C'), ('A', 'A'), ('A', 'A')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gravity model\n",
    "- Inspired by the Newtonian law of forces,one can imagine that the flow of trade between two countries might depend on the two “masses\" of t he countries involved and might be inversely proportional (not necessarily with a square power) to their reciprocal distance.\n",
    "$$T_{ij}=G(M^{\\beta_1}_i M^{\\beta_2}_j/D^{\\beta_3}_{ij})$$\n",
    "$T_{ij}$ indicates the trade between two countries $i,j$; the masses $M_{i,j}$ are characteristic of the countries; $i,j,D_{i,j}$ is their reciprocal distance (between the capitals), and $G$ is a constant.\n",
    "-  There are various explanations for the meaning of the masses $M_{i,j}$ for the countries $i,j$. \n",
    "- The simplest choice is to use the GDP of countries as the quantity $M$ describing the trade $F$ between two nations. \n",
    "- The values of the exponents $\\beta_{1,2,3}$ are determined from data by means of various methods of fitting.\n",
    "- Ref\n",
    "    - http://geoworld.pe.kr/geogrdic/html/9-021.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gravity model\n",
    "import scipy.optimize as optimization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate artificial data straight line with a=O and b=l \n",
    "# plus some noise.\n",
    "xdata = np.array([0.0, 1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "ydata = np.array([0.1, 0.9, 2.2, 2.8, 3.9, 5.1])\n",
    "\n",
    "sigma = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "x0 = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return a + b*x + c*x*x\n",
    "\n",
    "popt, pcov = optimization.curve_fit(func, xdata, ydata, x0, sigma)\n",
    "print(popt, \"\\n\", pcov)\n",
    "\n",
    "plt.plot(xdata, ydata, 'b-', label='data')\n",
    "plt.plot(xdata, func(xdata, *popt), 'r-', label='fit')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness model\n",
    "- Along a similar line of reasoning to that for the gravity model, there is a whole class of network models that are based on some “mass\" or quantity characteristic of the vertices. \n",
    "- This quantity indicated as “fitness\" determines the property of the network, starting from the degree of every node.\n",
    "- More particularly,the probability of drawing an edge is a function of the fitness of the vertices involved.\n",
    "\n",
    "\n",
    "- Aassign a real value $X_i$ to every vertex $i$ of the graph. This value can be taken from data or extracted from a probability distribution $\\rho(x)$.\n",
    "- Determine a function $f(x_i,x_j)$ giving the probability $p_{i,j}$ with which the two vertices $(i,j)$ will be connected.\n",
    "- According to the various possible choices for both the distribution $\\rho(x)$ and the linking probability $p_{i,j}$ different classes of networks appear.\n",
    "- The expected value $k(x)$ of the degree of a vertex whose fitness is $x$, we have\n",
    "$$k(x) = N\\int^\\infty_0\\rho(y)f(x, y)=NF(x)$$\n",
    "\n",
    "- Invert it and in the limit of large $N$ (where\n",
    "we can neglect finite corrections) we can write\n",
    "$$P(k) = \\rho\\Big[F^{-1}(\\frac{k}{n})\\Big]\\frac{d}{dk}F^{-1}(\\frac{k}{n})$$\n",
    "- If the fitnesses are exponentially distributed so that $x_i, x_j$  are extracted from a $\\rho(x) = Ae^{-x}$, where $A=1$ is the normalisation constant and the linking probability $p_{i,j}$ is a threshold function $p_{i,j}=\\Theta(x_i + x_j - z(N))$, we can obtain a scale-free network $P(k)\\propto k^{-2}$.\n",
    "\n",
    "\n",
    "- Ref\n",
    "    - https://en.wikipedia.org/wiki/Fitness_model_(network_theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fitness model\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# this is our z(N)\n",
    "ave_value = 1.0\n",
    "N = 5000\n",
    "\n",
    "def fitness_function():\n",
    "    return random.expovariate(4.0 / ave_value)\n",
    "\n",
    "def generate_function(x1, x2):\n",
    "    if x1 + x2 - ave_value < 0.0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "for n in range(N):\n",
    "    G.add_node(n, fitness=fitness_function())\n",
    "    \n",
    "node_list = G.nodes()\n",
    "\n",
    "# generate the graph adding ad edge for each possible couple of nodes\n",
    "for i1 in range(len(node_list)-1):\n",
    "    for i2 in range(i1+1, len(node_list)):\n",
    "        x1 = G.node[node_list[i1]]['fitness']\n",
    "        x2 = G.node[node_list[i2]]['fitness']\n",
    "        if generate_function(x1, x2) == 1:\n",
    "            G.add_edge(node_list[i1], node_list[i2])\n",
    "            \n",
    "degree_sequence = sorted(nx.degree(G).values(), reverse=True)\n",
    "plt.hist(degree_sequence, bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barabási-Albert model\n",
    "- While the number of countries and their reciprocal distance can be considered to be (at least for the latter) fairly stationary in time, this is not the case for routers or web sites. In such cases a better suited statistical model is necessary.\n",
    "- The most successful model of graph growth based on this totally different approach is the Barabási-Albert (BA) model (Barabási and Albert, 1999; Albert and Barabási, 2002).\n",
    "- In this model the number of vertices varies continuously in time; in particular, time is discretised and at every time step a new vertex is added. A simple procedure for building a BA network is to start from a small initial graph and for every time step:\n",
    "    1. introduce a new vertex in the system\n",
    "    2. link the vertex to the initial graph by drawing $m$ new edges; the destination vertices are chosen with a probability proportional to their degree. This means that\n",
    "    $$p=p(k_i)=\\frac{k_i}{\\sum_{j=1,n}k_j}.$$\n",
    "    \n",
    "    \n",
    "- Note that, since at every time step only one vertex enters, we have for the order $n$, that is, the number of vertices and the size $m$ of the network, respectively\n",
    "$$\\begin{align*} n&=n_0+t, \\\\ m&=\\frac{1}{2}\\sum_{j=1,n}k_i=mt+m_0 \\end{align*}$$\n",
    "\n",
    "\n",
    "- The degree of any vertex can only increase, the variation of the degree of one node in one time step will be given by how many edges we add $(m)$ times the probability $p(k)$ to get an edge from the newcomer vertex just added. This means\n",
    "$$\\frac{\\partial k_i}{\\partial t}=m_o\\Pi(k)=m\\frac{k_i}{\\sum_{j=1,n}k_j}=\\frac{mk_i}{2mt+m_0}$$\n",
    "\n",
    "\n",
    "- If we assume that the initial edges are $0$ (or in any case we study the behaviour for large $t$),we have\n",
    "$$\\frac{\\partial k_i}{\\partial t}=\\frac{k_i}{2t}\\rightarrow k_i(t)=m\\Big(\\frac{t}{t_i}\\Big)^{1/2}$$\n",
    "where $t_i$ is the time at which the vertex entered the systtem.\n",
    "\n",
    "\n",
    "- From this first result (the degree grows with the square root power of time) we can derive the form of the degree distribution. The basic idea is that we can use time and degree interchangeably, this means that the probability $P(k_i < k)$ that a vertex has\n",
    "a degree lower than $k$ is $P(k_i < k) = P(t_i > \\frac{m^2_0t}{k^2}$. We also know that enter at a constant rate so that the time distribution is uniform in time,that is $P(t) = A$, where the constant value of $A$ can be determined by imposing $A =\\int^n_0P(t) = An = 1$, so that $A = 1/n = 1/(n_0 +t)$. In this way, we write\n",
    "$$P(t_i > \\frac{m^2t}{k^2})=1-P(t_i\\leq\\frac{m^2t}{k^2})=1-\\frac{m^2t}{k^2}\\frac{1}{(n_0+t)}$$\n",
    "$$P(k)=\\frac{\\partial P(k_i > k)}{\\partial k}=\\frac{2m^2t}{(n_0 + t)}\\frac{1}{k^3}$$\n",
    "- Therefore, we find that the degree distribution is a power law with a value of the exponent $\\gamma = 3$.\n",
    "\n",
    "- Ref\n",
    "    - https://en.wikipedia.org/wiki/Barabási–Albert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Barabási-Albert model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N0 = 6\n",
    "p = 0.6\n",
    "new_nodes = 1000\n",
    "\n",
    "G = nx.gnp_random_graph(N0, p)\n",
    "\n",
    "for eti in range(new_nodes):\n",
    "    m = 3\n",
    "    new_eti = \"_\"+str(eti)\n",
    "    target_nodes = []\n",
    "    while m != 0:\n",
    "        part_sum = 0.0\n",
    "        rn = random.random()\n",
    "        for n in G.nodes():\n",
    "            base = part_sum\n",
    "            step = part_sum + G.degree(n)/(G.number_of_edges()*2.0)\n",
    "            part_sum = part_sum + G.degree(n)/(G.number_of_edges()*2.0)\n",
    "            if rn >= base and rn < step:\n",
    "                if n in target_nodes:\n",
    "                    break\n",
    "                target_nodes.append(n)\n",
    "                m = m - 1\n",
    "                break\n",
    "                \n",
    "    for n_tar in target_nodes:\n",
    "        G.add_edge(new_eti, n_tar)\n",
    "\n",
    "degree_sequence = sorted(nx.degree(G).values(), reverse=True)\n",
    "\n",
    "plt.hist(degree_sequence, bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction of networks\n",
    "- Reconstructing a network when only limited information is available represents one of the major challenges in the field of complex systems,especially those concerning socio-economics:\n",
    "\n",
    "#### Measuring likelihood of unknown configurations\n",
    "- (1) making optimal use of the available information, and (2) drawing as unbiased as possible conclusions on the unknown portion of the system.\n",
    "- MaxEnt (i.e. maximum entropy) principle\n",
    "$$S=-\\sum_G P(G)\\ln{P(G)}$$\n",
    "\n",
    "\n",
    "$$P(G)=\\frac{e^{-H(G)}}{Z}=\\frac{e^{-\\sum_a\\theta_a C_a}}{Z}$$\n",
    "where $H(G)$ sums up the available information on the network $G$ and $Z=\\sum_Ge^{-H(G)}$ normalises the probability coefficient to one. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the unknown parameters\n",
    "- The MaxEnt principle leaves us with the problem of estimating the unknown parameters $\\theta_i,\\forall i$.\n",
    "$$\\frac{\\partial\\mathcal{L}(\\overrightarrow{\\theta})}{\\partial \\theta_i} = 0, \\forall i$$ \n",
    "- The algorithm for estimating the parameters of the configuration model reads $k^*_i = x_ix_j / (1 +x_ix_j),\\forall i$. Notice that, in this case, the probability that any two nodes $i$ and $j$ establish a connection is driven by the value of their degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From null models to reconstruction methods\n",
    "- Enhanced Configuration Model (ECM)\n",
    "$$p_{ij} = \\frac{x_ix_jy_iy_j}{1+x_ix_jy_iy_j - y_iy_j}, \\langle w_{ij}\\rangle=\\frac{p_{ij}}{1-y_iy_j},$$\n",
    "whose unknown parameters can be estimated through solving the system\n",
    "$$\\begin{cases}\n",
    "k_i = \\sum_{j(\\neq i)}p_{ij},\\forall i \\\\\n",
    "s_i = \\sum_{j(\\neq i)}\\langle w_{ij}\\rangle, \\forall i\n",
    "\\end{cases}$$\n",
    "\n",
    "- the ECM tells us that creating a connection and reinforcing an existing connection are processes obeying different rules,driving nodes towards integration or segregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fitness model\n",
    "- The unknown parameters defining $P(G)$ can be estimated through the maximisation of the likelihood function $\\mathcal{L(\\overrightarrow{\\theta})}$. However, networks exist for which\n",
    "the probability that any two nodes interact can be explicitly written in terms of non- structural quantities which are typical of the system under analysis.\n",
    "- For the World Trade Web we have\n",
    "$$p^{WTW}_{ij} = \\frac{z\\ {GDP}_i\\ {GDP}_j}{1+z\\ {GDP}_i\\ {GDP}_j}$$\n",
    "where the extra parameter $z$ can be tuned to reproduce the observed number of links, $L(G) = \\sum_i\\sum_{j(\\neq i)}p^{WTW}_{ij}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping a network\n",
    "- It is noteworthy, this approach can be extended to deal with cases where the aforementioned information is known for <u>only some of the nodes</u>.\n",
    "- a “reduced\" likelihood estimation can be carried out,in order to determine $z$ (Cimini et al., 2015c; Musmeci et al.,2013):\n",
    "$$\\sum_{i\\in I}k_i=\\sum_{i\\in I}\\sum_{j(\\neq i)}\\tilde{p}_{ij}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
