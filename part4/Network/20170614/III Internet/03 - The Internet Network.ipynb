{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 \n",
    "# The Internet Network\n",
    "## Introduction\n",
    "- Network science has developed quickly over recent year because of the internet.\n",
    "- Internet : technically only the physical layer of PCs, computers, and servers connected by cables.\n",
    "- World Wide Web, Wikipedia, Facebook, Twitter...\n",
    "- [GGG(Giant global Graph)](https://en.wikipedia.org/wiki/Giant_Global_Graph) : to refer to the next revolution where all the information produced and stored in various services will be <u>aggregated, categorised, and distributed in various formats according to the user’s need</u>(by Tim Berners-Lee)\n",
    "\n",
    "## Data from CAIDA \n",
    "- *The Internet* is <u>the set of the various computers worldwide</u>, connected by cables, servers etc, it indicates a <u>physical framework</u>.\n",
    "- “Looking for something on the Internet\" : mean <u>browsing a web site</u> stored in one of those computers.\n",
    "- The existence of this network is due to <u>military research first</u> (how to build a network for communication able to work after bombing and destruction of some of its parts) , while <u>scientific needs</u> (how to efficiently share resource and information) appeared only late.\n",
    "- Protocole Suite(TCP/IP) - fixed as 1982, able to operate independently from the HW available.\n",
    "- Becasue of the redundacy of connections, provide high immunity from the deleterious effects of damage\n",
    "- So, no complete map ofthe Internet available.\n",
    "- <span style=\"font-family:Courier; font-size:1em;\">Traceroute</span> : traces the path data takes from one computer to another.\n",
    "- These “hops\" count the intermediate devices (like routers) through which data must pass between source and destination, rather than flowing directly over a simple cable. Each device along the data path constitutes a hop,or in other words is a vertex in the graph. Therefore a hop count gives the distance of two nodes in the Internet network.\n",
    "- Various projects have set up repositories of traceroute data,l while the most comprehensive repository is based in CAIDA (Center for Applied Internet Data Analysis)\n",
    "- The best source of data for the Internet is from the Center for Applied Internet Data Analysis(CAIDA), based at the University of Californica's San Diego Supercomputer Center.\n",
    "- CAIDA is \"a colloboration of different organisations in the commercial, goverment, and research sectors investigating practical and theoretical aspects of the Internet in order to:\n",
    "    - provide macroscopic insights into Internet infrastructure, behavior, usage, and evolution,\n",
    "    - foster a collaborative environment in which data can be acquired, analyzed, and (as appropriate) shared,\n",
    "    - improve the integrity of the field of Internet science,\n",
    "    - inform science, technology, and communications public policies.\"\n",
    "\n",
    "<img src=\"http://cheswick.com/ches/map/gallery/aug98-ip.gif\">\n",
    "<center>A snapshot of the global Internet map, realised by the Internet Mapping Project (http://cheswick.com/ches/map/) on August 1998</center>\n",
    "    \n",
    "## Visualisation\n",
    "- How to visually represent a graph\n",
    "- The bset visualisation is the one that reduces the number of crossing edges.\n",
    "- As in almost all cases of complex networks applications, the graphs are rather sparse, therefore, it is <u>not</u> particularly <u>efficient to keep in the memory the whole adjacency matrix</u>; rather a <u>better choice is to consider the list of edges</u>.\n",
    "- Tools\n",
    "    - [Pajek software](http://mrvar.fdv.uni-lj.si/pajek/)\n",
    "    - [Grephi](https://gephi.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network from SVG with the best node positioning\n",
    "import networkx as nx\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def Graph_from_SVG(stream):\n",
    "    G=nx.Graph()\n",
    "    attrs = {\n",
    "        \"line\" :  [\"x1\",\"y1\",\"x2\",\"y2\"]\n",
    "    }\n",
    "    \n",
    "    op = open(stream,\"r\")\n",
    "    xml = op.read()\n",
    "    \n",
    "    soup = BeautifulSoup(xml, 'lxml')\n",
    "    \n",
    "    count=0\n",
    "    node_diz={}\n",
    "    pos={}\n",
    "    for attr in attrs.keys():\n",
    "        tmps = soup.findAll(attr)\n",
    "        for t in tmps:\n",
    "            node1=(t['x1'],t['y1'])\n",
    "            node2=(t['x2'],t['y2'])            \n",
    "            if not node1 in node_diz:\n",
    "                node_diz[node1]=str(count)\n",
    "                pos[str(count)]=(float(node1[0]),float(node1[1]))\n",
    "                count+=1\n",
    "            if not node2 in node_diz:                \n",
    "                node_diz[node2]=str(count)\n",
    "                pos[str(count)]=(float(node2[0]),float(node2[1]))\n",
    "                count+=1\n",
    "            G.add_edge(node_diz[node1],node_diz[node2])\n",
    "            \n",
    "    #save the graph in an edge list format\n",
    "    nx.write_edgelist(G, \"./data/test_graph.dat\",data=False)\n",
    "    \n",
    "    return G,pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualisation tools\n",
    "# getting the network in the SVG format \n",
    "file=\"./data/test_graph.svg\"\n",
    "(G,pos)=Graph_from_SVG(file)\n",
    "\n",
    "#plot the optimal node distribution\n",
    "nx.draw(G, pos, node_size = 150, node_color='black')\n",
    "# nx.draw_networkx(G, pos, node_size = 100, node_color='black')\n",
    "#save the graph on a figure file\n",
    "savefig(\"./data/test_network_best.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotting the basic network\n",
    "G=nx.read_edgelist(\"./data/test_graph.dat\")\n",
    "# graphviz_pos=nx.graphviz_layout(G)\n",
    "graphviz_pos=nx.nx_pydot.graphviz_layout(G)\n",
    "nx.draw(G, graphviz_pos, node_size = 150, node_color='black')\n",
    "# nx.draw_networkx(G, pos, node_size = 100, node_color='black')\n",
    "#save the graph on a figure file\n",
    "savefig(\"./data/test_network_graphviz.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance or centrality\n",
    "- The centrality of a vertex or edge is generally perceived as <u>a measure of the importance of this element</u> within the whole network.\n",
    "<img src=\"./Fig.3.3.png\">\n",
    "<center><font size=-1>[Examples of A) degree centrality,B) closeness centrality,C) betweenness centrality, D) eigenvector centrality of the same graph.]</font></center>\n",
    "- 참고 : http://bab2min.tistory.com/554\n",
    "\n",
    "### Degree centrality(연결 중심성)\n",
    "- One “local\" measure of centrality is to look for <u>the vertices with the largest degrees</u>.\n",
    "- Being very well connected they are probably often visited by anyone travelling on the graph.\n",
    "- This quantity called “**degree centrality**\" is local since it can only be computed by checking the vertex itself and, in most cases, it represents <u>a fast and reasonably accurate quantity</u> to describe the importance of vertices in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Degree sequence\n",
    "degree_centrality = nx.degree(G)\n",
    "print(degree_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Original\n",
    "\n",
    "l=[]\n",
    "res = degree_centrality\n",
    "\n",
    "for n in G.nodes():\n",
    "#     if not res.has_key(n):\n",
    "    if not n in res:        \n",
    "        res[n] = 0.0\n",
    "    l.append(res[n])\n",
    "    \n",
    "nx.draw_networkx_edges(G, pos)\n",
    "for n in G.nodes():\n",
    "    list_nodes=[n]\n",
    "    color = str((res[n]-min(l))/float((max(l)-min(l))))\n",
    "    nx.draw_networkx_nodes(G, {n: pos[n]}, [n], \n",
    "                           node_size=100, \n",
    "                           node_color=color, cmap=plt.cm.gray)\n",
    "#     print(color)\n",
    "    \n",
    "savefig(\"./data/degree_200.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modified by etc.\n",
    "l=[]\n",
    "colors=[]\n",
    "res = degree_centrality\n",
    "\n",
    "for n in G.nodes():\n",
    "#     if not res.has_key(n):\n",
    "    if not n in res:        \n",
    "        res[n] = 0.0\n",
    "    l.append(res[n])\n",
    "\n",
    "for n in G.nodes():\n",
    "    list_nodes=[n]   # 도대체 용도가?\n",
    "    colors.append( str((res[n]-min(l))/float((max(l)-min(l)))))\n",
    "\n",
    "nx.draw_networkx_edges(G, pos)\n",
    "nx.draw_networkx_nodes(G, pos, G.nodes(), \n",
    "                       node_size=100, \n",
    "                       node_color=colors, cmap=plt.cm.Greys_r).set_edgecolor('k')\n",
    "# nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "    \n",
    "savefig(\"./data/degree_200.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closeness centrality(근접 중심성)\n",
    "- A non-local definition of centrality is <b>based on the notion of distance</b>.\n",
    "- The quantity is non-local since we need to inspect the whole graph to compute it.  <--??\n",
    "- **The lower the distance from the other vertices the larger is the closeness**.\n",
    "\n",
    "For vertex $i$, the closeness $c_i$ formula\n",
    "$$c_i=\\frac{1}{\\sum_{j\\neq i}d_{ij}}$$\n",
    "For networks that are not strongly connected, a viable alternative is harmonic centrality:\n",
    "$$c^h_i=\\sum_{j\\neq i} \\frac{1}{d_{ij}}=\\sum_{d_{ij} < \\infty, j\\neq i} \\frac{1}{d_{ij}}$$\n",
    "\n",
    "- To compute these centrality measures we need a function that computers all the distances from a root node. Use [BFS alorithm](https://en.wikipedia.org/wiki/Breadth-first_search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distance function\n",
    "def node_distance(G, root_node):\n",
    "    queue=[]\n",
    "    list_distances=[]\n",
    "    queue.append(root_node)\n",
    "    \n",
    "    # deleting the old keys\n",
    "    if 'distance' in G.node[root_node]:\n",
    "        for n in G.nodes():\n",
    "            del G.node[n]['distance']\n",
    "    G.node[root_node]['distance'] = 0\n",
    "    \n",
    "    while len(queue):\n",
    "        working_node = queue.pop(0)\n",
    "        for n in G.neighbors(working_node):\n",
    "            if len(G.node[n]) == 0:\n",
    "                G.node[n]['distance']=G.node[working_node]['distance']+1\n",
    "                queue.append(n)\n",
    "    \n",
    "    for n in G.nodes():\n",
    "        list_distances.append(((root_node,n), G.node[n]['distance']))\n",
    "        \n",
    "    return list_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Closeness\n",
    "norm=0.0\n",
    "diz_c={}\n",
    "l_values=[]\n",
    "colors=[]\n",
    "\n",
    "for n in G.nodes():\n",
    "    l = node_distance(G, n)\n",
    "    ave_length=0\n",
    "    for path in l:\n",
    "        ave_length += float(path[1])/(G.number_of_nodes()-1-0)  ## ?? -1-0\n",
    "        \n",
    "    norm += 1/ave_length\n",
    "    diz_c[n] =1 /ave_length\n",
    "    l_values.append(diz_c[n])\n",
    "\n",
    "for n in G.nodes():\n",
    "    list_nodes=[n]\n",
    "    colors.append(str((diz_c[n] - min(l_values)) / (max(l_values) - min(l_values))))\n",
    "  \n",
    "nx.draw_networkx_edges(G, pos)\n",
    "nx.draw_networkx_nodes(G, pos, G.nodes(), \n",
    "                       node_size=100, \n",
    "                       node_color=colors, cmap=plt.cm.Greys_r).set_edgecolor('k')\n",
    "\n",
    "savefig(\"./data/closeness_200.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness centrality(매개 중심성)\n",
    "- Another “non-local\" way to <u>measure the importance of one vertex or edge is to check how often we visit it when walking on the network</u>.\n",
    "    $$b(i)=\\sum_{\\substack{j,l = 1, n\\\\ i\\neq j\\neq l}}\\frac{D_{jl}(i)}{D_{jl}}$$\n",
    "-  $D_{jl}$ is the total number of different shortest paths (distances) going from $j$ to $l$ and $D_{jl}(i)$ is the subset of those distances passing through $i$. The sum runs over all pairs with $i\\neq j \\neq l$.\n",
    "- The larger the degree of a vertex, the larger is on average its betweenness; the two quantities are correlated and it is possible to connect the properties of the betweenness distribution to that of the degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Betweenness\n",
    "list_of_nodes=G.nodes()\n",
    "num_of_nodes=G.number_of_nodes()\n",
    "bc={}\n",
    "\n",
    "for i in range(num_of_nodes-1):\n",
    "    for j in range(i+1, num_of_nodes):\n",
    "        paths=nx.all_shortest_paths(G, source=list_of_nodes[i], target=list_of_nodes[j])\n",
    "        count=0.0\n",
    "        path_diz={}\n",
    "        for p in paths:\n",
    "            count+=1.0\n",
    "            for n in p[1:-1]:\n",
    "                if not n in path_diz:\n",
    "                    path_diz[n]=0.0\n",
    "                path_diz[n] += 1.0\n",
    "                \n",
    "        for n in path_diz.keys():\n",
    "            path_diz[n]=path_diz[n]/count\n",
    "            if not n in bc:\n",
    "                bc[n] = 0.0\n",
    "            bc[n] += path_diz[n]\n",
    "                            \n",
    "l=[]\n",
    "colors=[]\n",
    "res=bc\n",
    "for n in G.nodes():\n",
    "#     if not res.has_key(n):\n",
    "    if not n in res:\n",
    "        res[n]=0.0\n",
    "    l.append(res[n])\n",
    "    \n",
    "for n in G.nodes():\n",
    "    list_nodes=[n]\n",
    "    colors.append(str((res[n]-min(l))/(max(l)-min(l))))\n",
    "  \n",
    "nx.draw_networkx_edges(G, pos)\n",
    "nx.draw_networkx_nodes(G, pos, G.nodes(), \n",
    "                       node_size=100, \n",
    "                       node_color=colors, cmap=plt.cm.Greys_r).set_edgecolor('k')\n",
    "\n",
    "savefig(\"./data/betweenness_200.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Betweenness centrality is particulary <u>useful in the case of commnunity detection</u>.\n",
    "- it is a <u>measure of the “bridging\" properties of one vertex/edge</u> so that <u>edges with large betweenness are likely to bridge different communities</u>.\n",
    "- If we remove them we can isolate the communities present in the graph.\n",
    "- The idea is to recursively compute the betweenness of the various edges in the network and to remove those with the largest values. In this way,isolated communities emerge from the web of connections. \n",
    "\n",
    "### Eigenvector centrality(고유벡터 중심성)\n",
    "- Based on the spectral properties of the adjacency matrix $A$.\n",
    "- The centrality of a vertex $i$ as the average of the centrality of its neighbours\n",
    "$$c_i=\\frac{1}{\\lambda}\\sum_{j=1, N}a_{ij}c_j$$\n",
    "In its vectorial form the above equation\n",
    "$$A\\overrightarrow{c}=\\lambda\\overrightarrow{c}$$\n",
    "- That is, the centrality is an eigenvector of the adjacency matrix $A$, where $\\lambda$ is the corresponding eigenvalue.\n",
    "- To have a physical sense the above eigenvalue must be real, but in general this is not always ensured.\n",
    "- To partly overcome these problems it is a good choice to take $\\lambda$ as the largest (in absolute value) eigenvalue of matrix $A$.\n",
    "- By [Perron-Frobenius theorem](https://en.wikipedia.org/wiki/Perron–Frobenius_theorem), <u>if $A$ is irreducible, or equivalently if the graph is (strongly) connected, then the eigenvector $\\overrightarrow{c}$ is both unique and positive</u>.\n",
    "- Use [Von Mises (power) iteration method](https://en.wikipedia.org/wiki/Power_iteration). The idea is to <u>start with a good approximation of the eigenvector related to the largest eigenvalue</u> (dominant eigenvector), or <u>directly from a random one</u>, and <u>iterate the vector coefficients according to the relation</u>\n",
    "$$b_{k+1}=\\frac{Ab_k}{\\lvert\\lvert{Ab_k}\\rvert\\rvert}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Eigenvector centrality\n",
    "centrality = nx.eigenvector_centrality_numpy(G)\n",
    "\n",
    "l=[]\n",
    "colors=[]\n",
    "res=centrality\n",
    "\n",
    "for n in G.nodes():\n",
    "#     if not res.has_key(n):\n",
    "    if not n in res:\n",
    "        res[n]=0.0\n",
    "    l.append(res[n])\n",
    "    \n",
    "for n in G.nodes():\n",
    "    list_nodes=[n]\n",
    "    colors.append(str((res[n]-min(l))/(max(l)-min(l))))\n",
    "    \n",
    "nx.draw_networkx_edges(G, pos)\n",
    "nx.draw_networkx_nodes(G, pos, G.nodes(), \n",
    "                       node_size=100, \n",
    "                       node_color=colors, cmap=plt.cm.Greys_r).set_edgecolor('k')\n",
    "\n",
    "savefig(\"eigenvector_200.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness and resilience, giant component\n",
    "- Robustness and resilience are concepts often <u>invoked in the field of critical infrastructure</u>, as for example with the Internet, water pipelines, and electricity grid.\n",
    "- The first quantity i.e. **robustness** is more a static property referring to how well a system can resist an attack or failures, before being disrupted.\n",
    "- The second quantity, i.e. **resilience** is more dynamic and describes how a system can reshape itself to avoid being disrupted.\n",
    "<img src=\"./Fig.3.4.png\" width=300>\n",
    "<center><font size=-1>[An example of a network with two components]</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Generating the graph with two components\n",
    "G_test = nx.Graph()\n",
    "G_test.add_edges_from([('A', 'B'), ('A', 'C'), ('C', 'D'), ('C', 'E'),\n",
    "                       ('D', 'F'), ('D', 'H'), ('D', 'G'), ('E', 'G'),\n",
    "                       ('E', 'I')])\n",
    "G_test.add_node('X')\n",
    "nx.draw(G_test)\n",
    "# nx.draw(G_test, with_labels=True)\n",
    "\n",
    "savefig(\"components_200.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Giant component through a breadth first search\n",
    "def giant_component_size(G_input):\n",
    "    G=G_input.copy()\n",
    "    components=[]\n",
    "    node_list=G.nodes()\n",
    "    \n",
    "    while len(node_list) != 0:\n",
    "        root_node=node_list[0]\n",
    "        component_list=[]\n",
    "        component_list.append(root_node)\n",
    "        queue=[]\n",
    "        queue.append(root_node)\n",
    "        G.node[root_node]['visited'] = True\n",
    "        while len(queue):\n",
    "            working_node = queue.pop(0)\n",
    "            for n in G.neighbors(working_node):\n",
    "                if len(G.node[n]) == 0:\n",
    "                    G.node[n]['visited'] = True\n",
    "                    queue.append(n)\n",
    "                    component_list.append(n)\n",
    "        components.append((len(component_list), component_list))\n",
    "        # remove the nodes of the component just discoverd\n",
    "        for i in component_list:\n",
    "            node_list.remove(i)\n",
    "            \n",
    "    components.sort(reverse=True)\n",
    "    \n",
    "    GiantComponent = components[0][1]\n",
    "    SizeGiantComponent = components[0][0]\n",
    "    \n",
    "    return GiantComponent, len(components)\n",
    "\n",
    "(GCC, num_components) = giant_component_size(G_test)\n",
    "\n",
    "print(\"Giant Connected Component:\", GCC)\n",
    "print(\"Number of components:\", num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Breaking the GCC\n",
    "import copy\n",
    "\n",
    "def breaking_graph(H, node_list):\n",
    "    n_l = copy.deepcopy(node_list)\n",
    "    #iterate deleting from the GCC while the graph comprises \n",
    "    # one component (num_components=1)\n",
    "    num_components=1\n",
    "    count=0\n",
    "    \n",
    "    while num_components == 1:\n",
    "        count += 1\n",
    "        #select at random an element in the node list \n",
    "        #node_to_delete=random.choice(H.nodes())\n",
    "        #select a node according to the betweenness ranking \n",
    "        #(the last in the list)\n",
    "        node_to_delete=n_l.pop()\n",
    "        H.remove_node(node_to_delete)\n",
    "        num_components=nx.number_connected_components(H)\n",
    "    return count\n",
    "\n",
    "(GCC, num_components)=giant_component_size(G_test)\n",
    "\n",
    "G_GCC = G_test.subgraph(GCC)\n",
    "\n",
    "random_list=copy.deepcopy(G_GCC.nodes())\n",
    "random.shuffle(random_list)\n",
    "\n",
    "c=breaking_graph(G_GCC, random_list)\n",
    "\n",
    "print(\"num of iterrations:\", c)\n",
    "\n",
    "graphviz_pos=nx.nx_pydot.graphviz_layout(G_GCC)\n",
    "\n",
    "nx.draw(G_GCC, graphviz_pos, node_size=200, with_labels=True)\n",
    "\n",
    "savefig(\"./data/broken_component_200.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Breaking up the giant connected component randomly\n",
    "G_AS = nx.read_edgelist(\"./data/AS-19971108.dat\")\n",
    "print(\"number of nodes:\", G_AS.number_of_nodes(), \n",
    "      \"nubmer of edges:\", G_AS.number_of_edges())\n",
    "\n",
    "(GCC, num_components) = giant_component_size(G_AS)\n",
    "\n",
    "n_iter=1000\n",
    "count=0.0\n",
    "\n",
    "for i in range(n_iter):\n",
    "    G_GCC = G_AS.subgraph(GCC)\n",
    "    random_list=copy.deepcopy(G_GCC.nodes())\n",
    "    random.shuffle(random_list)\n",
    "    c=breaking_graph(G_GCC, random_list)\n",
    "    count += c\n",
    "    \n",
    "# graphviz_pos=nx.nx_pydot.graphviz_layout(G_AS)\n",
    "# nx.draw(G_AS, graphviz_pos, node_size=100, with_labels=True)\n",
    "    \n",
    "print(\"average iterations to break GCC:\", count/n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Breaking up the giant connected component with betweenness centrality\n",
    "\n",
    "import operator\n",
    "\n",
    "G_GCC = G_AS.subgraph(GCC)\n",
    "\n",
    "node_centrality = nx.betweenness_centrality(G_GCC, k=None, \n",
    "                                           normalized=True,\n",
    "                                           weight=None,\n",
    "                                           endpoints=False,\n",
    "                                           seed=None)\n",
    "\n",
    "sorted_bc = sorted(node_centrality.items(), key=operator.itemgetter(1))\n",
    "\n",
    "node_ranking=[]\n",
    "for e in sorted_bc:\n",
    "    node_ranking.append(e[0])\n",
    "    \n",
    "c=breaking_graph(G_GCC, node_ranking)\n",
    "\n",
    "# graphviz_pos=nx.nx_pydot.graphviz_layout(G_GCC)\n",
    "# nx.draw(G_GCC, graphviz_pos, node_size=20)\n",
    "\n",
    "print(\"num of iterations:\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Autonomous_system_(Internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
