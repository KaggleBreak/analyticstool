{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- e-commerce의 중요한 부분으로, 고객이 자신과 관계없는 매우 많은 후보 중에 원하는 아이템을 구매하고나 선택할 수 있도록 의사 결정을 도와줌. 수집해 온 이력 데이터를 바탕으로 사용자에게 구매 가능성이 높은 아이템을 제안\n",
    "\n",
    "- 추천 시스템 분류: 협업 필터링 (Collaborative Filtering), 콘텐츠 기반 필터링 (Content-Based Filtering), 연관 룰 (association rules), 로그 우도 방법 (log-likelyhood method), hybrid methods\n",
    "\n",
    "- 분석 데이터 세트: [MovieLens](http://grouplens.org/datasets/movielens) : 1,682개의 영화에 대해 943명의 관객이 평가한 100,000개의 영화 평점(1~5점)으로 구성. 각 관객은 최소 20개의 평점을 줌.\n",
    "\n",
    "\n",
    "[추천 시스템 알고리즘 참고자료](http://bahnsville.tistory.com/897)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 추천 시스템에서 데이터 집합을 정렬하기 위해 사용하는 주요 행렬과 대표적으로 사용하는 계랑 척도: 유틸리티 행렬, 유사도 척도\n",
    "## 1) 유틸리티 행렬 \n",
    "\n",
    "평점 $r_{ij}$은 사용자 $i$가 아이템 $j$를 얼마나 좋게 평가하는지 나타내고 유틸리티 행렬 $R$에 저장됨\n",
    "\n",
    "행 $i$: 사용자 $i$가 평가한 아이템 목록\n",
    "열 $j$: 아이템 $j$를 평가한 모든 사용자의 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import collections\n",
    "from scipy import linalg\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data\n",
    "df = pd.read_csv('./data/ml-100k/u.data',sep='\\t',header=None)\n",
    "#movie list\n",
    "df_info = pd.read_csv('./data/ml-100k/u.item',sep='|',header=None)\n",
    "movielist = [df_info[1].tolist()[indx]+';'+str(indx+1) for indx in xrange(len(df_info[1].tolist()))]\n",
    "nmovies = len(movielist)\n",
    "nusers = len(df[0].drop_duplicates().tolist())  \n",
    "\n",
    "min_ratings = 50\n",
    "movies_rated  = list(df[1]) \n",
    "counts = collections.Counter(movies_rated)\n",
    "dfout = pd.DataFrame(columns=['user']+movielist)\n",
    "\n",
    "toremovelist = []\n",
    "for i in range(1,nusers):\n",
    "    tmpmovielist = [0 for j in range(nmovies)]\n",
    "    dftmp =df[df[0]==i]\n",
    "    for k in dftmp.index:\n",
    "        if counts[dftmp.ix[k][1]]>= min_ratings:           \n",
    "           tmpmovielist[dftmp.ix[k][1]-1] = dftmp.ix[k][2]\n",
    "           \n",
    "        else:\n",
    "           toremovelist.append(dftmp.ix[k][1])\n",
    "            \n",
    "    dfout.loc[i] = [i]+tmpmovielist\n",
    "  \n",
    "toremovelist = list(set(toremovelist))\n",
    "dfout.drop(dfout.columns[toremovelist], axis=1, inplace=True)\n",
    "dfout.to_csv('data/utilitymatrix.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>Toy Story (1995);1</th>\n",
       "      <th>GoldenEye (1995);2</th>\n",
       "      <th>Four Rooms (1995);3</th>\n",
       "      <th>Get Shorty (1995);4</th>\n",
       "      <th>Copycat (1995);5</th>\n",
       "      <th>Twelve Monkeys (1995);7</th>\n",
       "      <th>Babe (1995);8</th>\n",
       "      <th>Dead Man Walking (1995);9</th>\n",
       "      <th>Richard III (1995);10</th>\n",
       "      <th>...</th>\n",
       "      <th>Cool Runnings (1993);1035</th>\n",
       "      <th>Hamlet (1996);1039</th>\n",
       "      <th>Forget Paris (1995);1041</th>\n",
       "      <th>Multiplicity (1996);1047</th>\n",
       "      <th>She's the One (1996);1048</th>\n",
       "      <th>Koyaanisqatsi (1983);1065</th>\n",
       "      <th>Shallow Grave (1994);1073</th>\n",
       "      <th>Reality Bites (1994);1074</th>\n",
       "      <th>Six Degrees of Separation (1993);1101</th>\n",
       "      <th>Some Kind of Wonderful (1987);1119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 604 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  Toy Story (1995);1  GoldenEye (1995);2  Four Rooms (1995);3  \\\n",
       "0   1.0                 5.0                 3.0                  4.0   \n",
       "1   2.0                 4.0                 0.0                  0.0   \n",
       "\n",
       "   Get Shorty (1995);4  Copycat (1995);5  Twelve Monkeys (1995);7  \\\n",
       "0                  3.0               3.0                      4.0   \n",
       "1                  0.0               0.0                      0.0   \n",
       "\n",
       "   Babe (1995);8  Dead Man Walking (1995);9  Richard III (1995);10  \\\n",
       "0            1.0                        5.0                    3.0   \n",
       "1            0.0                        0.0                    2.0   \n",
       "\n",
       "                  ...                  Cool Runnings (1993);1035  \\\n",
       "0                 ...                                        0.0   \n",
       "1                 ...                                        0.0   \n",
       "\n",
       "   Hamlet (1996);1039  Forget Paris (1995);1041  Multiplicity (1996);1047  \\\n",
       "0                 0.0                       0.0                       0.0   \n",
       "1                 0.0                       0.0                       0.0   \n",
       "\n",
       "   She's the One (1996);1048  Koyaanisqatsi (1983);1065  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "\n",
       "   Shallow Grave (1994);1073  Reality Bites (1994);1074  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "\n",
       "   Six Degrees of Separation (1993);1101  Some Kind of Wonderful (1987);1119  \n",
       "0                                    0.0                                 0.0  \n",
       "1                                    0.0                                 0.0  \n",
       "\n",
       "[2 rows x 604 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/utilitymatrix.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음 두 라인 출력한 것을 보면 영화이름;영화ID 로 구성. 평점을 50회 이하로 받은 영화는 유틸리티 행렬에서 제거해 칼럼이 604개.\n",
    "값이=0: 결측치. 사용자별 또는 아이템별 평균 평점으로 imputation을 해야 할 경우도 있음.\n",
    "\n",
    "유틸리티 행렬 $R$은 $N$(사용자) X $M$(아이템) 차원."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imputation(inp,Ri):\n",
    "    Ri = Ri.astype(float)\n",
    "    def userav():\n",
    "        for i in xrange(len(Ri)):\n",
    "            Ri[i][Ri[i]==0] = sum(Ri[i])/float(len(Ri[i][Ri[i]>0]))\n",
    "        return Ri\n",
    "    def itemav():\n",
    "        for i in xrange(len(Ri[0])):\n",
    "            Ri[:,i][Ri[:,i]==0] = sum(Ri[:,i])/float(len(Ri[:,i][Ri[:,i]>0]))\n",
    "        return Ri            \n",
    "    switch = {'useraverage':userav(),'itemaverage':itemav()}\n",
    "    return switch[inp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 유사도 척도\n",
    "\n",
    "- 코사인 유사도 (cosine similarity):\n",
    "\n",
    "<img src=\"img/eq5-1.cosine.png\",width=250,height=250>\n",
    "\n",
    "\n",
    "- 피어슨 유사도 (Pearson similarity):\n",
    "\n",
    "<img src=\"img/eq5-2.pearson.png\",width=350,height=250>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "두 척도는 평균이 0인 경우에 일치.\n",
    "\n",
    "sim() 함수는 두 벡터의 유사도를 평가할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 협업 필터링 방법 (Collaborative Filtering methods)\n",
    "\n",
    "## 사용자는 자신과 비슷한 사람들이 좋게 평가한 아이템을 좋아한다는 아이디어에 기반\n",
    "\n",
    "- 메모리 기반: 다른 사용자의 기호와 비교해 가장 비슷한 사용자의 기호로 특정 사용자의 평가를 추론\n",
    "\n",
    "- 모델 기반: 사람들이 좋아하는 아이템에 대한 평가 패턴을 추출하고 이 패턴을 따르는 미래의 평점을 예측\n",
    "\n",
    "## 특정 사용자를 위한 추천은 데이터에 비슷한 사람들이 얼마나 많이 있는가에 의존하기 때문에 엄청난 양의 데이터를 필요로 함\n",
    "\n",
    "- Cold start: 예측에 필요한 적정한 크기의 가용 데이터가 없는 상태에서 시작.\n",
    "\n",
    "- Warm start: 가용 데이터가 충분히 있는 상태로 시작.\n",
    "\n",
    "- CF와 CBF의 하이브리드 방식: 콜드 스타드를 극복하기 위함.\n",
    "\n",
    "## 문제점\n",
    "\n",
    "- 확장성 (scalability) : 사용자와 아이템의 개수에 비례해서 연산이 증가하는 문제점 있음 => 병렬 처리의 필요성\n",
    "\n",
    "- 희소성 (sparsity) : 사용자가 평가하는 아이템의 개수가 작을 경우 유틸리티 행렬의 희소성이 생김\n",
    "\n",
    "## 2-1. 메모리 기반 협업 필터링 (Memory-Based Collaborative Filtering)\n",
    "\n",
    ": 유틸리티 행렬을 이용해 사용자와 아이템 간의 유사도를 계산\n",
    "\n",
    ": 확장성과 콜트 스타트 이슈\n",
    "\n",
    ": 많은 사용 시스템에서 유틸리티 행렬이 크거나 아주 작을 경우에 적용\n",
    "\n",
    "\n",
    "### 2-1-1. 사용자 기반 협업 필터링 (User-Based Collaborative Filtering)\n",
    "\n",
    ": 현재 사용자와 가거에 비슷한 평가를 사용했던 사용자를 찾기 위해 k-NN 방식을 사용. 이 때 누락 평점을 가중 평균으로 대신 사용.\n",
    "\n",
    ": 사용자 i와 아직 평가되지 않는 아이템 j에 대해 다음과 같은 단계를 실행한다.\n",
    "\n",
    "1) 유사도 척도 s를 사용해서 아이템 j에 대해 평점을 줬던 가장 비슷한 사용자 K를 찾는다.\n",
    "\n",
    "2) 사용자 i가 아직 평가하지 않은 아이템 j에 대해 평점을 예측한다. K의 평점을 가중 평균해 계산한다.\n",
    "\n",
    "<img src=\"img/eq5-3.userBasedCF.png\",width=350,height=250>\n",
    "\n",
    "이 때 사용자 i와 k의 평균 평점은 주관적 판단을 보상하기 위해 사용.\n",
    "\n",
    "균질적인(homogeneous) 평점으로 비교하기 위해 사용자별 평점 분포를 정규화시킬 수 있음.\n",
    "\n",
    "<img src=\"img/eq5-4.userBasedCF.png\",width=350,height=250>\n",
    "\n",
    "$\\alpha_j$, $\\alpha_k$ 는 사용자 i와 k의 평점에 대한 표준 편차. 입력 파라미터 K개의 (20~50) 이웃을 갖는다.\n",
    "\n",
    "피어슨 상관관계는 상관관계식에서 사용자의 평균 평점을 빼기 때문에 사용자 비교가 쉬우며 코사인 유사도보다 결과가 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine \n",
    "def sim(x,y,metric='cos'):\n",
    "    if metric == 'cos':\n",
    "       return 1.-cosine(x,y)\n",
    "    else:#correlation\n",
    "       return pearsonr(x,y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CF_userbased(u_vec,K,data,indxs=False):\n",
    "    def FindKNeighbours(r,data,K):\n",
    "        neighs = []\n",
    "        cnt=0\n",
    "        for u in xrange(len(data)):\n",
    "            if data[u,r]>0 and cnt<K:\n",
    "               neighs.append(data[u])   \n",
    "               cnt +=1 \n",
    "            elif cnt==K:\n",
    "               break\n",
    "        return np.array(neighs)\n",
    "        \n",
    "    def CalcRating(u_vec,r,neighs):\n",
    "        rating = 0.\n",
    "        den = 0.\n",
    "        for j in xrange(len(neighs)):\n",
    "            rating += neighs[j][-1]*float(neighs[j][r]-neighs[j][neighs[j]>0][:-1].mean())\n",
    "            den += abs(neighs[j][-1])\n",
    "        if den>0:\n",
    "            rating = np.round(u_vec[u_vec>0].mean()+(rating/den),0)\n",
    "        else:\n",
    "            rating = np.round(u_vec[u_vec>0].mean(),0)\n",
    "        if rating>5:\n",
    "            return 5.\n",
    "        elif rating<1:\n",
    "            return 1.\n",
    "        return rating \n",
    "    #add similarity col\n",
    "    data = data.astype(float)\n",
    "    nrows = len(data)\n",
    "    ncols = len(data[0])\n",
    "    data_sim = np.zeros((nrows,ncols+1))\n",
    "    data_sim[:,:-1] = data\n",
    "    #calc similarities:\n",
    "    for u in xrange(nrows):\n",
    "        if np.array_equal(data_sim[u,:-1],u_vec)==False: #list(data_sim[u,:-1]) != list(u_vec):\n",
    "           data_sim[u,ncols] = sim(data_sim[u,:-1],u_vec,'pearson')\n",
    "        else:\n",
    "           data_sim[u,ncols] = 0.\n",
    "    #order by similarity:\n",
    "    data_sim =data_sim[data_sim[:,ncols].argsort()][::-1]\n",
    "    #find the K users for each item not rated:\n",
    "    u_rec = np.zeros(len(u_vec))\n",
    "    for r in xrange(ncols):\n",
    "        if u_vec[r]==0:\n",
    "            #FindKNeighbours: 사용자 평점 백터인 u_vec과 가장 비슷한 사용자 K를 찾는다\n",
    "            neighs = FindKNeighbours(r,data_sim,K)\n",
    "            #CalcRating: Calculate the predicted rating (분포 교정을 하지 않지만 예측 평점>5 or <1인 경우 각각 5,1로 조정)\n",
    "            u_rec[r] = CalcRating(u_vec,r,neighs)\n",
    "    if indxs:\n",
    "            #take out the rated movies\n",
    "            seenindxs = [indx for indx in xrange(len(u_vec)) if u_vec[indx]>0]\n",
    "            u_rec[seenindxs] = -1\n",
    "            recsvec = np.argsort(u_rec)[::-1][np.argsort(u_rec)>0]\n",
    "        \n",
    "            return recsvec    \n",
    "    return u_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-2. 아이템 기반 협업 필터링 (Item-Based Collaborative Filtering)\n",
    "\n",
    ": 사용자가 아닌 아이템에 대해 유사도가 계산된다는 점을 제외하고 개념적으로 사용자 기반 (CF)와 동일\n",
    "\n",
    ": 사용자 수가 아이템 수보다 매우 커질 경우 아이템 유사도를 사전에 계산함으로써 좀 더 확장성 있는 추천 시스템을 제공. \n",
    "\n",
    "알고리즘\n",
    "\n",
    "1) 유사도 측정치 s를 이용해 사용자 i가 이미 평가한 아이템 중 가장 비슷한 아이템 K개를 찾는다.\n",
    "\n",
    "2) K개의 아이템 평점을 가중 평균해 예측 평점으로 계산한다.\n",
    "\n",
    "<img src=\"img/eq5-5.itemBasedCF.png\",width=200>\n",
    "\n",
    "\n",
    "양수의 $P_{ij}$를 구하기 위해 양수의 유사도만 더하는 것으로 제한 (아이템 평점보다 최고의 아이템을 추천하는데 관심이 있다면 아이템을 상대적으로 정렬)\n",
    "\n",
    "K = 20~30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CF_itembased(object):\n",
    "    def __init__(self,data):\n",
    "        #calc item similarities matrix\n",
    "        nitems = len(data[0])\n",
    "        self.data = data\n",
    "        self.simmatrix = np.zeros((nitems,nitems))\n",
    "        for i in xrange(nitems):\n",
    "            for j in xrange(nitems):\n",
    "                if j>=i:#triangular matrix\n",
    "                   self.simmatrix[i,j] = sim(data[:,i],data[:,j])\n",
    "                else:\n",
    "                   self.simmatrix[i,j] = self.simmatrix[j,i]\n",
    "\n",
    "    # GetKSimItemsperUser: 사용자가 평가하지 않은 아이템과 유사도가 가장 높은 아이템 중 사용자가 과거에 평가했던 K개의 아이템을 찾는다\n",
    "    def GetKSimItemsperUser(self,r,K,u_vec):\n",
    "        items = np.argsort(self.simmatrix[r])[::-1]\n",
    "        items = items[items!=r]\n",
    "        cnt=0\n",
    "        neighitems = []\n",
    "        for i in items:\n",
    "            if u_vec[i]>0 and cnt<K:\n",
    "               neighitems.append(i)\n",
    "               cnt+=1\n",
    "            elif cnt==K:\n",
    "               break\n",
    "        return neighitems\n",
    "        \n",
    "    # CalcRating: 사용자 평점이 없는 경우 예측하며 가중 평균 평점을 계산하여 이웃을 찾을 수 없는 경우 이것으로 설정.\n",
    "    # u_vec:사용자 평점 벡터, 유틸리티 행렬의 행 벡터\n",
    "    def CalcRating(self,r,u_vec,neighitems):\n",
    "        rating = 0.\n",
    "        den = 0.\n",
    "        for i in neighitems:\n",
    "            rating +=  self.simmatrix[r,i]*u_vec[i]\n",
    "            den += abs(self.simmatrix[r,i])\n",
    "        if den>0:\n",
    "            rating = np.round(rating/den,0)\n",
    "        else:\n",
    "            rating = np.round(self.data[:,r][self.data[:,r]>0].mean(),0)\n",
    "        return rating\n",
    "        \n",
    "    def CalcRatings(self,u_vec,K,indxs=False):\n",
    "        #u_rec = copy.copy(u_vec)\n",
    "        u_rec = np.zeros(len(u_vec))\n",
    "        for r in xrange(len(u_vec)):\n",
    "            if u_vec[r]==0:\n",
    "               neighitems = self.GetKSimItemsperUser(r,K,u_vec)\n",
    "               #calc predicted rating\n",
    "               u_rec[r] = self.CalcRating(r,u_vec,neighitems)\n",
    "        if indxs:\n",
    "            #take out the rated movies\n",
    "            seenindxs = [indx for indx in xrange(len(u_vec)) if u_vec[indx]>0]\n",
    "            u_rec[seenindxs]=-1\n",
    "            recsvec = np.argsort(u_rec)[::-1][np.argsort(u_rec)>0]\n",
    "        \n",
    "            return recsvec\n",
    "        return u_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-2-1. 슬롭원 (SlopeOne) : 가장 단순한 아이템 기반 협업 필터링\n",
    "\n",
    "행렬 요소 $d_{ij}$가 아이템 i와 j의 평점 차이 평균인 행렬 D를 계산해보자.\n",
    "\n",
    "<img src=\"img/eq5-6.slopeOne.png\",width=200>\n",
    "\n",
    "\n",
    "$n_{k}^{ij}$: 아이템 i와 j에게 평점을 모두 준 사용자를 세는 변수, $\\sum_{k=1 }^{N}n_{k}^{ij}$: i와 j에게 평점을 모두 준 사용자 수\n",
    "\n",
    "알고리즘은 '아이템 기반 협업 필터링' 절에서 설명했던 것과 동일. (차이가 나는 부분은 행렬뿐)\n",
    "\n",
    "1) 아이템 j와 가장 차가 작은 아이템 K를 찾는다.\n",
    "\n",
    "2) 예측 평점을 다음의 가중 평균으로 계산한다.\n",
    "\n",
    "<img src=\"img/eq5-6-2.slopeOne2.png\",width=250>\n",
    "\n",
    "\n",
    "다른 CF알고리즘에 비해 매우 단순하지만 대체로 정확하고 계산 비용 낮고 구현이 쉬움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SlopeOne(object):\n",
    "    def __init__(self,Umatrix):\n",
    "        #calc item similarities matrix\n",
    "        nitems = len(Umatrix[0])\n",
    "        self.difmatrix = np.zeros((nitems,nitems))\n",
    "        self.nratings = np.zeros((nitems,nitems))\n",
    "        def diffav_n(x,y):\n",
    "            xy = np.vstack((x, y)).T\n",
    "            xy = xy[(xy[:,0]>0) & (xy[:,1]>0)]\n",
    "            nxy = len(xy)\n",
    "            if nxy == 0:\n",
    "                #print 'no common'\n",
    "                return [1000.,0]\n",
    "            return [float(sum(xy[:,0])-sum(xy[:,1]))/nxy,nxy]\n",
    "            \n",
    "        # difmatrix: 아이템 i,j의 차 $d_{ij}$를 계산하는데 사용\n",
    "        for i in xrange(nitems):\n",
    "            for j in xrange(nitems):\n",
    "                if j>=i:#triangular matrix                 \n",
    "                   self.difmatrix[i,j],self.nratings[i,j] = diffav_n(Umatrix[:,i],Umatrix[:,j])\n",
    "                else:\n",
    "                   self.difmatrix[i,j] = -self.difmatrix[j,i]\n",
    "                   self.nratings[i,j] = self.nratings[j,i]\n",
    "        \n",
    "    # GetKSimItemsperUser: K개의 최근접 이웃을 찾기 위해 행렬 difmatrix에서 가장 작은 값을 찾는다.\n",
    "    def GetKSimItemsperUser(self,r,K,u_vec):\n",
    "        items = np.argsort(self.difmatrix[r])\n",
    "        items = items[items!=r]\n",
    "        cnt=0\n",
    "        neighitems = []\n",
    "        for i in items:\n",
    "            if u_vec[i]>0 and cnt<K:\n",
    "               neighitems.append(i)\n",
    "               cnt+=1\n",
    "            elif cnt==K:\n",
    "               break\n",
    "        return neighitems\n",
    "        \n",
    "    def CalcRating(self,r,u_vec,neighitems):\n",
    "        rating = 0.\n",
    "        den = 0.\n",
    "        for i in neighitems:\n",
    "            if abs(self.difmatrix[r,i])!=1000: #difmatrix 디폴트=1000\n",
    "               rating +=  (self.difmatrix[r,i]+u_vec[i])*self.nratings[r,i]\n",
    "               den += self.nratings[r,i]\n",
    "        if den==0:\n",
    "            #print 'no similar diff'\n",
    "            return 0.\n",
    "        rating = np.round(rating/den,0)\n",
    "        # 예측 평균이 5보다 크거나 1보다 작으면 각각 5,1로 설정\n",
    "        if rating >5:\n",
    "            return 5.\n",
    "        elif rating <1.:\n",
    "            return 1.\n",
    "        return rating\n",
    "        \n",
    "    def CalcRatings(self,u_vec,K):\n",
    "        #u_rec = copy.copy(u_vec)\n",
    "        u_rec = np.zeros(len(u_vec))\n",
    "        for r in xrange(len(u_vec)):\n",
    "            if u_vec[r]==0:\n",
    "               neighitems = self.GetKSimItemsperUser(r,K,u_vec)\n",
    "               #calc predicted rating\n",
    "               u_rec[r] = self.CalcRating(r,u_vec,neighitems)\n",
    "        return u_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. 모델 기반 협업 필터링 (Model-Based Collaborative Filtering)\n",
    "\n",
    ": 유틸리티 행렬을 이용해 사용자와 아이템 평가 패턴을 추출하는 모델을 생성\n",
    "\n",
    ": 원래의 행렬을 만들거나 근사해 평점을 예측하는 방식\n",
    "\n",
    ": 행렬 분해 - 유틸리티 행렬로부터 원래의 행렬인 사용자 행렬과 아이템 행렬을 만드는 과정\n",
    "\n",
    "\n",
    "### 2-2-1. 교대 최소 제곱법 (Alternative Least Square)\n",
    "\n",
    "행렬 R을 분해하는 가장 간단한 방법. 각 사용자와 아이템은 차원 K의 특징 공간에 표현된다.\n",
    "\n",
    "<img src=\"img/eq5-8.utilityMatrix.png\",width=140>\n",
    "\n",
    "여기서 $P(N \\times K)$는 특징 공간에서의 새로운 사용자 행렬, $Q(M \\times K)$는 특징 공간에서의 아이템 행렬.\n",
    "\n",
    "<img src=\"img/eq5-8.ALS.png\",width=650>\n",
    "\n",
    "$\\gamma$: 정규화 파라미터, 학습 파라미터인 벡터 $p_i$와 $q_j^T$에 패널티를 주어 값이 커지지 않게 보장함으로써 과적합(overfitting)을 방지.\n",
    "\n",
    "$Mc_{ij}$는 사용자 i와 아이템 j의 쌍이 실제 평가됐는지 체크. $r_{ij}>0$이면 1, 아니면 0\n",
    "\n",
    "사용자 벡터 $P_i$와 아이템 벡터 $q_j$에 대해 J를 미분해 0으로 하면 다음 두 식을 얻을 수 있음.\n",
    "\n",
    "<img src=\"img/eq5-8.piqj.png\",width=300>\n",
    "\n",
    "교대로 행렬 P, Q를 고정하면 이 식은 최소 제곱 알고리즘 (least square algorithm)으로 직접 풀림."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ALS(Umatrix, K, iterations=50, l=0.001, tol=0.001): #변수 l은 정규화 파라미터 lamda이며 디폴트로 0.001로 설정\n",
    "\n",
    "    nrows = len(Umatrix)\n",
    "    ncols = len(Umatrix[0])  \n",
    "    P = np.random.rand(nrows,K)\n",
    "    Q = np.random.rand(ncols,K)\n",
    "    Qt = Q.T\n",
    "    err = 0.\n",
    "    Umatrix = Umatrix.astype(float)\n",
    "    mask = Umatrix>0. #행령 Mc는 변수 mask로 정의.\n",
    "    mask[mask==True]=1\n",
    "    mask[mask==False]=0\n",
    "    mask = mask.astype(np.float64, copy=False)\n",
    "    for it in xrange(iterations):\n",
    "        for u, mask_u in enumerate(mask):\n",
    "            #np.linalg.solve로 최소 제곱 문제 풀다\n",
    "            P[u] = np.linalg.solve(np.dot(Qt, np.dot(np.diag(mask_u), Qt.T)) + l*np.eye(K), \n",
    "                                np.dot(Qt, np.dot(np.diag(mask_u), Umatrix[u].T))).T\n",
    "        for i, mask_i in enumerate(mask.T):\n",
    "            Qt[:,i] = np.linalg.solve(np.dot(P.T, np.dot(np.diag(mask_i), P)) + l*np.eye(K),\n",
    "                                np.dot(P.T, np.dot(np.diag(mask_i), Umatrix[:,i])))                            \n",
    "        err=np.sum((mask*(Umatrix - np.dot(P, Qt)))**2)\n",
    "        if err < tol:\n",
    "            break\n",
    "    return np.round(np.dot(P,Qt),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정밀도는 떨어지지만 구현이 매우 쉽고 병렬 처리가 쉬워 속도가 빠르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-2. 확률 내리막 경사법 (Stochastic Gradient Descent)\n",
    "\n",
    "[위키피디아 SGD 설명](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) [한글 참고자료](http://darkpgmr.tistory.com/133)\n",
    "\n",
    "유틸리티 행렬 R을 근사하기 때문에 행렬 분해의 하위 유형에 속함\n",
    "\n",
    "<img src=\"img/eq5-8.utilityMatrix.png\",width=140>\n",
    "\n",
    "행렬 P(NXK)와 Q(MXK)는 K차원의 잠재 특징 공간에서의 사용자와 아이템을 나타냄.\n",
    "\n",
    "근사 평점은 다음과 같이 표현.\n",
    "\n",
    "행렬 $\\widehat{R}$은 정규화된 제곱 오차 $e^2_{ij}$의 최소화 문제를 풀 때 사용. 방법은 ALS와 동일 (3장에서 비용 함수 J).\n",
    "\n",
    "(p203 중간 수식)\n",
    "\n",
    "\n",
    "최소화 문제는 내리막 경사법을 이용해 풀 수 있음.\n",
    "\n",
    "<img src=\"img/eq5-9.ALS.png\",width=300>\n",
    "\n",
    "$\\alpha$는 학습률이고 오류는 $e_{ij}=\\left ( r_{ij}-\\sum_{K}^{k=l}p_{lk}q_{kj} \\right )$임.\n",
    "\n",
    "\n",
    "두 식을 교대로 적용하면서 수렴할 때까지 R을 찾음.\n",
    "\n",
    "SGD: 다음절에 나오는 SVD보다 병렬처리가 쉽지만 (처리 속도 빠름) 정밀도가 떨어짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SGD(Umatrix, K, iterations=100, alpha=0.00001, l=0.001, tol=0.001):\n",
    "    #디폴트: iterations=100, alpha=0.00001, l=0.001, tol=0.001, 평가되지 않은 아이템은 계산에 고려하지 않는다.\n",
    "\n",
    "    nrows = len(Umatrix)\n",
    "    ncols = len(Umatrix[0])  \n",
    "    P = np.random.rand(nrows,K)\n",
    "    Q = np.random.rand(ncols,K)\n",
    "    Qt = Q.T\n",
    "    cost=-1\n",
    "    for it in xrange(iterations):\n",
    "        for i in xrange(nrows):\n",
    "            for j in xrange(ncols):\n",
    "                if Umatrix[i][j] > 0:\n",
    "                   eij = Umatrix[i][j] -np.dot(P[i,:],Qt[:,j])\n",
    "                   for k in xrange(K):\n",
    "                       P[i][k] += alpha*(2*eij*Qt[k][j]-l*P[i][k])\n",
    "                       Qt[k][j] += alpha*(2*eij*P[i][k]-l*Qt[k][j]) \n",
    "        cost = 0\n",
    "        for i in xrange(nrows):\n",
    "            for j in xrange(ncols):\n",
    "                if Umatrix[i][j]>0:\n",
    "                   cost += pow(Umatrix[i][j]-np.dot(P[i,:],Qt[:,j]),2)\n",
    "                   for k in xrange(K):\n",
    "                       cost += float(l/2.0)*(pow(P[i][k],2)+pow(Qt[k][j],2))\n",
    "        if cost < tol:\n",
    "           break\n",
    "    return np.round(np.dot(P,Qt),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-3. 비음수 행렬 분해 (Non-negative Matrix Factorization)\n",
    "\n",
    "[최적화 방법](https://www.slideshare.net/madvirus/pca-svd)\n",
    "\n",
    "행렬 R을 두개의 행렬의 곱으로 분해하되 행렬의 요소가 음수가 아닌 방법들의 그룹.\n",
    "\n",
    "<img src=\"img/eq5-10.SGD.png\",width=150>\n",
    "\n",
    "$\\alpha$는 어떤 정규화 항을 사용할지 정의하는 파라미터. 0: 제곱 정규화, 1: 라소 정규화, 나머지: 두 방법의 혼합\n",
    "\n",
    "$\\gamma$는 정규화 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "def NMF_alg(Umatrix,K,inp='none',l=0.001):\n",
    "    R_tmp = copy.copy(Umatrix)\n",
    "    R_tmp = R_tmp.astype(float)\n",
    "    #imputation\n",
    "    if inp != 'none':\n",
    "        R_tmp = imputation(inp,Umatrix)\n",
    "    nmf = NMF(n_components=K,alpha=l)\n",
    "    P = nmf.fit_transform(R_tmp) #P는 fit_transform을 통해 구함\n",
    "    R_tmp = np.dot(P,nmf.components_) #Q^T 행렬은 nmf.components\n",
    "    return R_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬 분해가 되기 전에 대체가 실행 될 수도 있음. 유틸리티 행렬은 양의 값(평점)을 갖기 때문에 유틸리티 행렬 값을 예측하는데 매우 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-4. 특이값 분해 (Singular Value Decomposition) (기대치 최적화, Expectation Maximization과 함께 적용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SVD 위키피디아 설명](http://en.wikipedia.org/wiki/Singular_value_decomposition) [특잇값](https://ko.wikipedia.org/wiki/특잇값)\n",
    "\n",
    "행렬을 U, $\\sigma$, V로 분해해 근사하는 차원 축소 기법 (2장 참조)\n",
    "\n",
    "초기에 각 사용자별 결측 데이터를 평가할 때 대체가 필요한데, 유틸리티 행렬의 각행의 평균 혹은 열의 평균, 또는 둘의 조합이 사용됨.\n",
    "\n",
    "유틸리티 행렬에 SVD를 적용하면서 EM 알고리즘(기대치 최대화)을 함께 적용 가능.\n",
    "\n",
    "1. m-step $\\hat{R}=SVD(\\hat{})$\n",
    "\n",
    "2. e-step $\\hat{r}_{ij}=\\left\\{\\begin{matrix}\n",
    "r_{\\hat{ij}} \\quad if \\enspace r_{ij} \\enspace is \\enspace filled \\enspace with \\enspace by \\enspace the \\enspace user\\\\ \n",
    "\\hat{r}_{ij} \\enspace else \\enspace (missing  \\enspace data)\n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "제곱 오차의 합이 지정된 허용 오차보다 작아질 때까지 반복한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "# m-step\n",
    "\n",
    "def SVD(Umatrix,K,inp='none'):\n",
    "    R_tmp = copy.copy(Umatrix)\n",
    "    R_tmp = R_tmp.astype(float)\n",
    "    #imputation\n",
    "    if inp != 'none':\n",
    "        R_tmp = imputation(inp,Umatrix)     \n",
    "\n",
    "    means = np.array([ R_tmp[i][R_tmp[i]>0].mean() for i in xrange(len(R_tmp))]).reshape(-1,1)\n",
    "    R_tmp = R_tmp-means\n",
    "    svd = TruncatedSVD(n_components=K, random_state=4)\n",
    "    R_k = svd.fit_transform(R_tmp)\n",
    "    R_tmp = svd.inverse_transform(R_k)\n",
    "    R_tmp = means+R_tmp\n",
    "    \n",
    "    return np.round(R_tmp,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#e-step\n",
    "def SVD_EM(Umatrix,K,inp='none',iterations=50,tol=0.001):\n",
    "    R_tmp = copy.copy(Umatrix)\n",
    "    R_tmp = R_tmp.astype(float)\n",
    "    nrows = len(Umatrix)\n",
    "    ncols = len(Umatrix[0])\n",
    "    #imputation\n",
    "    if inp != 'none':\n",
    "        R_tmp = imputation(inp,Umatrix)\n",
    "    #define svd\n",
    "    svd = TruncatedSVD(n_components=K, random_state=4)\n",
    "    err = -1\n",
    "    for it in xrange(iterations):\n",
    "        #m-step\n",
    "        R_k = svd.fit_transform(R_tmp)\n",
    "        R_tmp = svd.inverse_transform(R_k)\n",
    "        #e-step and error evaluation\n",
    "        err = 0\n",
    "        for i in xrange(nrows):\n",
    "            for j in xrange(ncols):\n",
    "                if Umatrix[i][j]>0:\n",
    "                   err += pow(Umatrix[i][j]-R_tmp[i][j],2)\n",
    "                   R_tmp[i][j] = Umatrix[i][j]                   \n",
    "                   \n",
    "        if err < tol:\n",
    "            print it,'toll reached!'\n",
    "            break\n",
    "    return np.round(R_tmp,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 콘텐트 기반 필터링 방법 (Content-Based Filtering)\n",
    "\n",
    "아이템의 설명 데이터에 의존해 사용자의 특징을 추출하는 방법.\n",
    "\n",
    "각 영화는 G 차원의 이진 벡터 $m_j$로 설명됨. 벡터 $m_j$의 요소는 영화 j가 속하는 장르에는 1, 아닌 경우 0.\n",
    "\n",
    "유틸리티 행렬을 저장한 데이터 프레임 dfout이 주어졌을 때 이진 벡터 $m_j$는 다음의 스크립트를 통해 MovieLens 데이터베이스에서 데이터 프레임으로 수집됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id  unknown  Action  Adventure  Animation  Children's  Comedy  Crime  \\\n",
      "0         1        0       0          0          1           1       1      0   \n",
      "1         2        0       1          1          0           0       0      0   \n",
      "2         3        0       0          0          0           0       0      0   \n",
      "3         4        0       1          0          0           0       1      0   \n",
      "4         5        0       0          0          0           0       0      1   \n",
      "\n",
      "   Documentary  Drama  Fantasy  Film-Noir  Horror  Musical  Mystery  Romance  \\\n",
      "0            0      0        0          0       0        0        0        0   \n",
      "1            0      0        0          0       0        0        0        0   \n",
      "2            0      0        0          0       0        0        0        0   \n",
      "3            0      1        0          0       0        0        0        0   \n",
      "4            0      1        0          0       0        0        0        0   \n",
      "\n",
      "   Sci-Fi  Thriller  War  Western  \n",
      "0       0         0    0        0  \n",
      "1       0         1    0        0  \n",
      "2       0         1    0        0  \n",
      "3       0         0    0        0  \n",
      "4       0         1    0        0  \n"
     ]
    }
   ],
   "source": [
    "#matrix movies's content\n",
    "movieslist = [int(m.split(';')[-1]) for m in dfout.columns[1:]]\n",
    "moviescats = ['unknown','Action','Adventure','Animation','Children\\'s','Comedy','Crime','Documentary',\n",
    "              'Drama','Fantasy','Film-Noir','Horror','Musical','Mystery',\n",
    "              'Romance','Sci-Fi','Thriller','War','Western']\n",
    "dfout_movies =  pd.DataFrame(columns=['movie_id']+moviescats)\n",
    "startcatsindx = 5\n",
    "cnt= 0\n",
    "for m in movieslist:\n",
    "    dfout_movies.loc[cnt] = [m]+df_info.iloc[m-1][startcatsindx:].tolist()\n",
    "    cnt +=1 \n",
    "print dfout_movies.head()\n",
    "\n",
    "dfout_movies.to_csv('data/movies_content.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "목표: 사용자가 각 장르를 얼마나 좋아하는지를 나타내는 필드를 갖는 사용자 프로파일을 생성하는 것.\n",
    "\n",
    "단점: 아이템에 대한 콘텐츠 설명 데이터가 늘 존재하지 않아 항상 사용할 수는 없음.\n",
    "\n",
    "장점: 특정 사용자를 위한 추천이 다른 사용자의 평점과 관련. 아이템에 대한 사용자 평점의 부족으로 발생하는 콜드 스타트 문제는 생기지 않음.\n",
    "\n",
    "<b>2가지 접근 방식</b>\n",
    "\n",
    "1. 장르별로 사용자가 본 영화의 평균 평점과 연관된 사용자 프로파일을 생성한 후 코사인 유사도를 사용해 사용자 선호도와 가장 유사한 영화를 찾는다.\n",
    "\n",
    "2. 정규화된 선형 회귀 분석 모델: 폄점과 영화 특징으로부터 사용자 프로파일 특징을 생성해 사용자가 아직 보지 않은 영화의 평점을 사용자 프로파일을 이용해 예윽"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. 아이템 특징 평균 방법 (Item Feature Average Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CBF_averageprofile(object):\n",
    "    def __init__(self,Movies,Movieslist):\n",
    "        #calc user profiles:\n",
    "        self.nfeatures = len(Movies[0])\n",
    "        self.Movieslist = Movieslist \n",
    "        self.Movies = Movies\n",
    "        \n",
    "    def GetRecMovies(self,u_vec,indxs=False):\n",
    "        #generate user profile\n",
    "        nmovies = len(u_vec)\n",
    "        nfeatures = self.nfeatures\n",
    "        mean_u = u_vec[u_vec>0].mean()\n",
    "        diff_u = u_vec-mean_u\n",
    "        features_u = np.zeros(nfeatures).astype(float)\n",
    "        cnts = np.zeros(nfeatures)\n",
    "        for m in xrange(nmovies):\n",
    "            if u_vec[m]>0:#u has rated m\n",
    "               features_u += self.Movies[m]*(diff_u[m])\n",
    "               cnts += self.Movies[m]\n",
    "        #average:\n",
    "        for m in xrange(nfeatures):\n",
    "            if cnts[m]>0:\n",
    "               features_u[m] = features_u[m]/float(cnts[m])\n",
    "               \n",
    "        #calc sim:\n",
    "        sims = np.zeros(nmovies)\n",
    "        for m in xrange(nmovies):\n",
    "            if u_vec[m]==0:#sim only for movies not yet rated by the user\n",
    "               sims[m] = sim(features_u,self.Movies[m])\n",
    "        #order movies\n",
    "        order_movies_indxs = np.argsort(sims)[::-1] \n",
    "        if indxs:\n",
    "            return order_movies_indxs\n",
    "        return self.Movieslist[order_movies_indxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. 정규화된 선형 회귀 분석 방법 (Regularized linear regression method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CBF_regression(object):\n",
    "    def __init__(self,Movies,Umatrix,alpha=0.01,l=0.0001,its=50,tol=0.001):\n",
    "        #calc parameters:\n",
    "        self.nfeatures = len(Movies[0])+1#intercept\n",
    "        nusers = len(Umatrix)\n",
    "        nmovies = len(Umatrix[0])\n",
    "        #add intercept col\n",
    "        movies_feats = np.ones((nmovies,self.nfeatures))\n",
    "        movies_feats[:,1:] = Movies\n",
    "        self.movies_feats = movies_feats.astype(float)\n",
    "        \n",
    "        #set Umatrix as float\n",
    "        self.Umatrix = Umatrix.astype(float)\n",
    "        #initialize the matrix:\n",
    "        Pmatrix = np.random.rand(nusers,self.nfeatures)\n",
    "        Pmatrix[:,0]=1.\n",
    "        err = 0.\n",
    "        cost = -1\n",
    "        for it in xrange(its):\n",
    "            print 'it:',it,' -- ',cost\n",
    "            for u in xrange(nusers):\n",
    "                for f in xrange(self.nfeatures):                    \n",
    "                    if f==0:#no regularization\n",
    "                        for m in xrange(nmovies):\n",
    "                            if self.Umatrix[u,m]>0:\n",
    "                               diff = np.dot(Pmatrix[u],self.movies_feats[m])-self.Umatrix[u,m]\n",
    "                               Pmatrix[u,f] += -alpha*(diff*self.movies_feats[m][f])\n",
    "                    else:\n",
    "                        for m in xrange(nmovies):\n",
    "                            if self.Umatrix[u,m]>0:\n",
    "                               diff = np.dot(Pmatrix[u],self.movies_feats[m])-self.Umatrix[u,m]\n",
    "                               Pmatrix[u,f] += -alpha*(diff*self.movies_feats[m][f] +l*Pmatrix[u][f])        \n",
    "                \n",
    "            cost = 0\n",
    "            for u in xrange(nusers):\n",
    "                for m in xrange(nmovies):\n",
    "                    if self.Umatrix[u][m]>0:\n",
    "                       cost += 0.5*pow(Umatrix[u][m]-np.dot(Pmatrix[u],self.movies_feats[m]),2)\n",
    "                for f in xrange(1,self.nfeatures):\n",
    "                    cost += float(l/2.0)*(pow(Pmatrix[u][f],2))\n",
    "            if cost < tol:\n",
    "               print 'err',cost\n",
    "               break\n",
    "        self.Pmatrix = Pmatrix\n",
    "        \n",
    "    def CalcRatings(self,u_vec):\n",
    "        #find u_vec\n",
    "        s = 0.\n",
    "        u_feats = np.zeros(len(self.Pmatrix[0]))\n",
    "        #in case the user is not present in the utility matrix find the most similar\n",
    "        for u in xrange(len(self.Umatrix)):\n",
    "            #print self.Umatrix[u]\n",
    "            tmps = sim(self.Umatrix[u],u_vec)\n",
    "            if tmps > s:\n",
    "                s = tmps\n",
    "                u_feats = self.Pmatrix[u]\n",
    "            if s == 1.:\n",
    "                break\n",
    "        new_vec = np.zeros(len(u_vec))\n",
    "        for r in xrange(len(u_vec)):\n",
    "            if u_vec[r]==0:\n",
    "                new_vec[r] = np.dot(u_feats,self.movies_feats[r])\n",
    "        return new_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 추천 시스템 학습을 위한 연관 규칙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AssociationRules(object):\n",
    "    def __init__(self,Umatrix,Movieslist,min_support=0.1,min_confidence=0.1,likethreshold=3):\n",
    "        self.min_support = min_support\n",
    "        self.min_confidence = min_confidence\n",
    "        self.Movieslist = Movieslist\n",
    "        #transform utility matrix to sets of liked items\n",
    "        nitems = len(Umatrix[0])\n",
    "        transactions = []\n",
    "        for u in Umatrix:\n",
    "            s = [i for i in xrange(len(u)) if u[i]>likethreshold]\n",
    "            if len(s)>0:\n",
    "               transactions.append(s)\n",
    "        #find sets of 2 items\n",
    "        flat = [item for sublist in transactions for item in sublist]\n",
    "        inititems = map(frozenset,[ [item] for item in frozenset(flat)])\n",
    "        set_trans = map(set, transactions)\n",
    "        sets_init, self.dict_sets_support = self.filterSet(set_trans, inititems)\n",
    "        setlen = 2\n",
    "        items_tmp = self.combine_lists(sets_init, setlen)\n",
    "        self.freq_sets, sup_tmp = self.filterSet(set_trans, items_tmp)\n",
    "        self.dict_sets_support.update(sup_tmp)\n",
    "        self.ass_matrix = np.zeros((nitems,nitems))\n",
    "        for freqset in self.freq_sets:\n",
    "            #print 'freqset',freqset\n",
    "            list_setitems = [frozenset([item]) for item in freqset]\n",
    "            #print \"freqSet\", freqset, 'H1', list_setitems\n",
    "            self.calc_confidence_matrix(freqset, list_setitems)\n",
    "        \n",
    "    def filterSet(self,set_trans, likeditems):\n",
    "        itemscnt = {}\n",
    "        for id in set_trans:\n",
    "            for item in likeditems:\n",
    "                if item.issubset(id):\n",
    "                    itemscnt.setdefault(item, 0)\n",
    "                    itemscnt[item] += 1\n",
    "        num_items = float(len(set_trans))\n",
    "        freq_sets = []\n",
    "        dict_sets = {}\n",
    "        for key in itemscnt:\n",
    "            support = itemscnt[key] / num_items\n",
    "            if support >= self.min_support:\n",
    "                freq_sets.insert(0, key)\n",
    "            dict_sets[key] = support\n",
    "        return freq_sets, dict_sets\n",
    "        \n",
    "    def combine_lists(self,freq_sets, setlen):\n",
    "        setitems_list = []\n",
    "        nsets = len(freq_sets)\n",
    "        for i in range(nsets):\n",
    "            for j in range(i + 1, nsets):\n",
    "                setlist1 = list(freq_sets[i])[:setlen - 2]\n",
    "                setlist2 = list(freq_sets[j])[:setlen - 2]\n",
    "                if set(setlist1) == set(setlist2):\n",
    "                    setitems_list.append(freq_sets[i].union(freq_sets[j]))\n",
    "        return setitems_list\n",
    "        \n",
    "    def calc_confidence_matrix(self,freqset, list_setitems):\n",
    "        for target in list_setitems:\n",
    "            confidence = self.dict_sets_support[freqset] / self.dict_sets_support[freqset - target]\n",
    "            if confidence >= self.min_confidence:\n",
    "                self.ass_matrix[list(freqset - target)[0]][list(target)[0]] = confidence\n",
    "                \n",
    "    def GetRecItems(self,u_vec,indxs=False):\n",
    "        vec_recs = np.dot(u_vec,self.ass_matrix)\n",
    "        sortedweight = np.argsort(vec_recs)\n",
    "        seenindxs = [indx for indx in xrange(len(u_vec)) if u_vec[indx]>0]\n",
    "        seenmovies = np.array(self.Movieslist)[seenindxs]\n",
    "        #remove seen items\n",
    "        recitems = np.array(self.Movieslist)[sortedweight]\n",
    "        recitems = [m for m in recitems if m not in seenmovies]\n",
    "        if indxs:\n",
    "            vec_recs[seenindxs]=-1\n",
    "            recsvec = np.argsort(vec_recs)[::-1][np.argsort(vec_recs)>0]\n",
    "            return recsvec\n",
    "        return recitems[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 로그 우도비 추천 시스템 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogLikelihood(object):\n",
    "    def __init__(self,Umatrix,Movieslist,likethreshold=3):\n",
    "        self.Movieslist = Movieslist\n",
    "        #calculate loglikelihood ratio for each pair\n",
    "        self.nusers = len(Umatrix)\n",
    "        self.Umatrix =Umatrix\n",
    "        self.likethreshold = likethreshold\n",
    "        self.likerange = range(self.likethreshold+1,5+1)\n",
    "        self.dislikerange = range(1,self.likethreshold+1)\n",
    "        self.loglikelihood_ratio()\n",
    "\n",
    "    def calc_k(self,a,b):\n",
    "        tmpk = [[0 for j in range(2)] for i in range(2)]\n",
    "        for ratings in self.Umatrix:\n",
    "            if ratings[a] in self.likerange and ratings[b] in self.likerange:\n",
    "               tmpk[0][0] += 1\n",
    "            if ratings[a] in self.likerange and ratings[b] in self.dislikerange:\n",
    "                tmpk[0][1] += 1\n",
    "            if ratings[a] in self.dislikerange and ratings[b] in self.likerange:\n",
    "                tmpk[1][0] += 1\n",
    "            if ratings[a] in self.dislikerange and ratings[b] in self.dislikerange:\n",
    "                tmpk[1][1] += 1\n",
    "        return tmpk\n",
    "        \n",
    "    def calc_llr(self,k_matrix):\n",
    "        Hcols=Hrows=Htot=0.0\n",
    "        if sum(k_matrix[0])+sum(k_matrix[1])==0:\n",
    "            return 0.\n",
    "        invN = 1.0/(sum(k_matrix[0])+sum(k_matrix[1])) \n",
    "        for i in range(0,2):\n",
    "            if((k_matrix[0][i]+k_matrix[1][i])!=0.0):\n",
    "               Hcols += invN*(k_matrix[0][i]+k_matrix[1][i])*math.log((k_matrix[0][i]+k_matrix[1][i])*invN )#sum of rows\n",
    "            if((k_matrix[i][0]+k_matrix[i][1])!=0.0):\n",
    "               Hrows += invN*(k_matrix[i][0]+k_matrix[i][1])*math.log((k_matrix[i][0]+k_matrix[i][1])*invN )#sum of cols\n",
    "            for j in range(0,2):\n",
    "                if(k_matrix[i][j]!=0.0):\n",
    "                   Htot +=invN*k_matrix[i][j]*math.log(invN*k_matrix[i][j])\n",
    "        return 2.0*(Htot-Hcols-Hrows)/invN\n",
    "\n",
    "    def loglikelihood_ratio(self):\n",
    "        nitems = len(self.Movieslist)\n",
    "        self.items_llr= pd.DataFrame(np.zeros((nitems,nitems))).astype(float)\n",
    "        for i in xrange(nitems):\n",
    "            for j in xrange(nitems):\n",
    "                if(j>=i):\n",
    "                   tmpk=self.calc_k(i,j)\n",
    "                   self.items_llr.ix[i,j] = self.calc_llr(tmpk)\n",
    "                else:\n",
    "                   self.items_llr.ix[i,j] = self.items_llr.iat[j,i]\n",
    "        \n",
    "    def GetRecItems(self,u_vec,indxs=False):\n",
    "        items_weight = np.dot(u_vec,self.items_llr)\n",
    "        sortedweight = np.argsort(items_weight)\n",
    "        seenindxs = [indx for indx in xrange(len(u_vec)) if u_vec[indx]>0]\n",
    "        seenmovies = np.array(self.Movieslist)[seenindxs]\n",
    "        #remove seen items\n",
    "        recitems = np.array(self.Movieslist)[sortedweight]\n",
    "        recitems = [m for m in recitems if m not in seenmovies]\n",
    "        if indxs:\n",
    "            items_weight[seenindxs]=-1\n",
    "            recsvec = np.argsort(items_weight)[::-1][np.argsort(items_weight)>0]\n",
    "            return recsvec\n",
    "        return recitems[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 하이브리드 추천 시스템\n",
    "\n",
    "- 가중(Weighted): CF와 CBF 예측 평점을 가중 평균으로 합침\n",
    "\n",
    "- 혼합(Mixed): CF와 CBF 예측 영화를 각각 구한 후 하나의 목록에 합병\n",
    "\n",
    "- 교대(Switched): 특정 조건으로 CF 예측 혹은 CBF 예측을 사용\n",
    "\n",
    "- 특징 조합 (Feature combination): CF와 CBF 특징을 함께 고려해 가장 유사한 사용자나 아이템을 찾음\n",
    "\n",
    "- 특징 증가 (Feature augmentation): 특징 조합과 유사하지만 추가 특징을 사용해 평점을 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Hybrid_cbf_cf(object):\n",
    "    def __init__(self,Movies,Movieslist,Umatrix):\n",
    "        #calc user profiles:\n",
    "        self.nfeatures = len(Movies[0])\n",
    "        self.Movieslist = Movieslist \n",
    "        self.Movies = Movies.astype(float)\n",
    "        self.Umatrix_mfeats = np.zeros((len(Umatrix),len(Umatrix[0])+self.nfeatures))\n",
    "        means = np.array([ Umatrix[i][Umatrix[i]>0].mean() for i in xrange(len(Umatrix))]).reshape(-1,1)\n",
    "        diffs = np.array([ [Umatrix[i][j]-means[i] if Umatrix[i][j]>0 else 0. \n",
    "                            for j in xrange(len(Umatrix[i]))  ] for i in xrange(len(Umatrix))])\n",
    "        self.Umatrix_mfeats[:,:len(Umatrix[0])] = Umatrix#diffs\n",
    "        self.nmovies = len(Movies)\n",
    "        #calc item features for each user\n",
    "        for u in xrange(len(Umatrix)):\n",
    "            u_vec = Umatrix[u]\n",
    "            self.Umatrix_mfeats[u,len(Umatrix[0]):] = self.GetUserItemFeatures(u_vec)\n",
    "            \n",
    "    def GetUserItemFeatures(self,u_vec):\n",
    "        mean_u = u_vec[u_vec>0].mean()\n",
    "        #diff_u = u_vec-mean_u\n",
    "        features_u = np.zeros(self.nfeatures).astype(float)\n",
    "        cnts = np.zeros(self.nfeatures)\n",
    "        for m in xrange(self.nmovies):\n",
    "            if u_vec[m]>0:#u has rated m\n",
    "               features_u += self.Movies[m]*u_vec[m]#self.Movies[m]*(diff_u[m])\n",
    "               cnts += self.Movies[m]\n",
    "        #average:\n",
    "        for m in xrange(self.nfeatures):\n",
    "            if cnts[m]>0:\n",
    "               features_u[m] = features_u[m]/float(cnts[m])\n",
    "        return features_u\n",
    "    def CalcRatings(self,u_vec,K):\n",
    "        def FindKNeighbours(r,data,K):\n",
    "            neighs = []\n",
    "            cnt=0\n",
    "            for u in xrange(len(data)):\n",
    "                if data[u,r]>0 and cnt<K:\n",
    "                   neighs.append(data[u])   \n",
    "                   cnt +=1 \n",
    "                elif cnt==K:\n",
    "                   break\n",
    "            return np.array(neighs)\n",
    "        \n",
    "        def CalcRating(u_vec,r,neighs):\n",
    "            rating = 0.\n",
    "            den = 0.\n",
    "            for j in xrange(len(neighs)):\n",
    "                rating += neighs[j][-1]*float(neighs[j][r]-neighs[j][neighs[j]>0][:-1].mean())\n",
    "                den += abs(neighs[j][-1])\n",
    "            if den>0:\n",
    "                rating = np.round(u_vec[u_vec>0].mean()+(rating/den),0)\n",
    "            else:\n",
    "                rating = np.round(u_vec[u_vec>0].mean(),0)\n",
    "            if rating>5:\n",
    "                return 5.\n",
    "            elif rating<1:\n",
    "                return 1.\n",
    "            return rating\n",
    "        #add similarity col\n",
    "        nrows = len(self.Umatrix_mfeats)\n",
    "        ncols = len(self.Umatrix_mfeats[0])\n",
    "        data_sim = np.zeros((nrows,ncols+1))\n",
    "        data_sim[:,:-1] = self.Umatrix_mfeats\n",
    "        u_rec = np.zeros(len(u_vec))\n",
    "        #calc similarities:\n",
    "        mean = u_vec[u_vec>0].mean()\n",
    "        u_vec_feats = u_vec#np.array([u_vec[i]-mean if u_vec[i]>0 else 0 for i in xrange(len(u_vec))])\n",
    "        u_vec_feats = np.append(u_vec_feats,self.GetUserItemFeatures(u_vec))\n",
    "        \n",
    "        for u in xrange(nrows):\n",
    "            if np.array_equal(data_sim[u,:-1],u_vec)==False: #list(data_sim[u,:-1]) != list(u_vec):\n",
    "               data_sim[u,ncols] = sim(data_sim[u,:-1],u_vec_feats)\n",
    "            else:\n",
    "               data_sim[u,ncols] = 0.\n",
    "        #order by similarity:\n",
    "        data_sim =data_sim[data_sim[:,ncols].argsort()][::-1]\n",
    "        #find the K users for each item not rated:\n",
    "        \n",
    "        for r in xrange(self.nmovies):\n",
    "            if u_vec[r]==0:\n",
    "               neighs = FindKNeighbours(r,data_sim,K)\n",
    "               #calc the predicted rating\n",
    "               u_rec[r] = CalcRating(u_vec,r,neighs)\n",
    "        return u_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Hybrid_svd(object):\n",
    "    def __init__(self,Movies,Movieslist,Umatrix,K,inp):\n",
    "        #calc user profiles:\n",
    "        self.nfeatures = len(Movies[0])\n",
    "        self.Movieslist = Movieslist \n",
    "        self.Movies = Movies.astype(float)\n",
    "        \n",
    "        R_tmp = copy.copy(Umatrix)\n",
    "        R_tmp = R_tmp.astype(float)\n",
    "        #imputation\n",
    "        \n",
    "        if inp != 'none':\n",
    "            R_tmp = imputation(inp,Umatrix)\n",
    "        Umatrix_mfeats = np.zeros((len(Umatrix),len(Umatrix[0])+self.nfeatures))\n",
    "        means = np.array([ Umatrix[i][Umatrix[i]>0].mean() for i in xrange(len(Umatrix))]).reshape(-1,1)\n",
    "        diffs = np.array([ [float(Umatrix[i][j]-means[i]) \n",
    "                            if Umatrix[i][j]>0 else float(R_tmp[i][j]-means[i]) for j in xrange(len(Umatrix[i]))  ] \n",
    "                          for i in xrange(len(Umatrix))])\n",
    "        Umatrix_mfeats[:,:len(Umatrix[0])] = diffs#R_tmp\n",
    "        self.nmovies = len(Movies)\n",
    "        #calc item features for each user\n",
    "        for u in xrange(len(Umatrix)):\n",
    "            u_vec = Umatrix[u]\n",
    "            Umatrix_mfeats[u,len(Umatrix[0]):] = self.GetUserItemFeatures(u_vec)\n",
    "        \n",
    "        #calc svd\n",
    "        svd = TruncatedSVD(n_components=K, random_state=4)\n",
    "        R_k = svd.fit_transform(Umatrix_mfeats)\n",
    "        R_tmp = means+svd.inverse_transform(R_k)\n",
    "        self.matrix = np.round(R_tmp[:,:self.nmovies],0)\n",
    "        \n",
    "        \n",
    "    def GetUserItemFeatures(self,u_vec):\n",
    "        mean_u = u_vec[u_vec>0].mean()\n",
    "        diff_u = u_vec-mean_u\n",
    "        features_u = np.zeros(self.nfeatures).astype(float)\n",
    "        cnts = np.zeros(self.nfeatures)\n",
    "        for m in xrange(self.nmovies):\n",
    "            if u_vec[m]>0:#u has rated m\n",
    "               features_u += self.Movies[m]*(diff_u[m])#self.Movies[m]*u_vec[m]\n",
    "               cnts += self.Movies[m]\n",
    "        #average:\n",
    "        for m in xrange(self.nfeatures):\n",
    "            if cnts[m]>0:\n",
    "               features_u[m] = features_u[m]/float(cnts[m])\n",
    "        return features_u "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 추천 시스템 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(df,k):\n",
    "    val_num = int(len(df)/float(k))\n",
    "    print val_num\n",
    "    df_trains = []\n",
    "    df_vals = []\n",
    "    for i in xrange(k):\n",
    "        start_val = (k-i-1)*val_num\n",
    "        end_val = start_val+val_num\n",
    "        df_trains.append(pd.concat([df[:start_val],df[end_val:]]))\n",
    "        df_vals.append(df[start_val:end_val])\n",
    "\n",
    "    return df_trains,df_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def HideRandomRatings(u_vec, ratiovals=0.5):\n",
    "    u_test = np.zeros(len(u_vec))\n",
    "    u_vals = np.zeros(len(u_vec))\n",
    "    cnt = 0\n",
    "    nratings = len(u_vec[u_vec>0])\n",
    "    for i in xrange(len(u_vec)):\n",
    "        if u_vec[i]>0:        \n",
    "            if bool(random.getrandbits(1)) or cnt>=int(nratings*ratiovals):\n",
    "                u_test[i]=u_vec[i]\n",
    "            else:#random choice to hide the rating:\n",
    "                cnt +=1\n",
    "                u_vals[i]=u_vec[i]\n",
    "    return u_test,u_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  Toy Story (1995);1  GoldenEye (1995);2  Four Rooms (1995);3  \\\n",
      "0     1                   5                   3                    4   \n",
      "1     2                   4                   0                    0   \n",
      "2     3                   0                   0                    0   \n",
      "3     4                   0                   0                    0   \n",
      "\n",
      "   Get Shorty (1995);4  Copycat (1995);5  Twelve Monkeys (1995);7  \\\n",
      "0                    3                 3                        4   \n",
      "1                    0                 0                        0   \n",
      "2                    0                 0                        0   \n",
      "3                    0                 0                        0   \n",
      "\n",
      "   Babe (1995);8  Dead Man Walking (1995);9  Richard III (1995);10  \\\n",
      "0              1                          5                      3   \n",
      "1              0                          0                      2   \n",
      "2              0                          0                      0   \n",
      "3              0                          0                      0   \n",
      "\n",
      "                  ...                  Cool Runnings (1993);1035  \\\n",
      "0                 ...                                          0   \n",
      "1                 ...                                          0   \n",
      "2                 ...                                          0   \n",
      "3                 ...                                          0   \n",
      "\n",
      "   Hamlet (1996);1039  Forget Paris (1995);1041  Multiplicity (1996);1047  \\\n",
      "0                   0                         0                         0   \n",
      "1                   0                         0                         0   \n",
      "2                   0                         0                         0   \n",
      "3                   0                         0                         0   \n",
      "\n",
      "   She's the One (1996);1048  Koyaanisqatsi (1983);1065  \\\n",
      "0                          0                          0   \n",
      "1                          0                          0   \n",
      "2                          0                          0   \n",
      "3                          0                          0   \n",
      "\n",
      "   Shallow Grave (1994);1073  Reality Bites (1994);1074  \\\n",
      "0                          0                          0   \n",
      "1                          0                          0   \n",
      "2                          0                          0   \n",
      "3                          0                          0   \n",
      "\n",
      "   Six Degrees of Separation (1993);1101  Some Kind of Wonderful (1987);1119  \n",
      "0                                      0                                   0  \n",
      "1                                      0                                   0  \n",
      "2                                      0                                   0  \n",
      "3                                      0                                   0  \n",
      "\n",
      "[4 rows x 604 columns]\n",
      "check::: 603 -- 603\n",
      "188\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv('data/utilitymatrix.csv')\n",
    "print df.head(4)\n",
    "df_movies = pd.read_csv('data/movies_content.csv')\n",
    "movies = df_movies.values[:,1:]\n",
    "print 'check:::',len(df.columns[1:]),'--',len(df_movies)\n",
    "movieslist = list(df.columns[1:])\n",
    "#k-fold cv 5 folds\n",
    "nfolds = 5\n",
    "df_trains,df_vals = cross_validation(df,nfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nmovies = len(df_vals[0].values[:,1:][0])\n",
    "vals_vecs_folds = []\n",
    "tests_vecs_folds = []\n",
    "for i in xrange(nfolds):\n",
    "    u_vecs = df_vals[i].values[:,1:]\n",
    "    vtests = np.empty((0,nmovies),float)\n",
    "    vvals = np.empty((0,nmovies),float)\n",
    "    for u_vec in u_vecs:\n",
    "        u_test,u_vals = HideRandomRatings(u_vec)\n",
    "        vvals = np.vstack([vvals,u_vals])\n",
    "        vtests = np.vstack([vtests,u_test])\n",
    "    vals_vecs_folds.append(vvals)\n",
    "    tests_vecs_folds.append(vtests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 평균 제곱근 오차 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SE(u_preds,u_vals):\n",
    "    nratings = len(u_vals)\n",
    "    se = 0.\n",
    "    cnt = 0\n",
    "    for i in xrange(nratings):\n",
    "        if u_vals[i]>0:\n",
    "           se +=  (u_vals[i]-u_preds[i])*(u_vals[i]-u_preds[i])\n",
    "           cnt += 1\n",
    "    return se,cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "fold: 5\n",
      "user_userbased rmse: 1.01381431911 -- 39972\n",
      "user_itembased rmse: 1.0301785707 -- 39972\n",
      "slope one rmse: 1.07792084094 -- 39972\n",
      "cbfcf rmse: 1.0134317593 --- 39972\n"
     ]
    }
   ],
   "source": [
    "err_itembased = 0.\n",
    "cnt_itembased = 0\n",
    "err_userbased = 0.\n",
    "cnt_userbased = 0\n",
    "err_slopeone = 0.\n",
    "cnt_slopeone = 0\n",
    "err_cbfcf = 0.\n",
    "cnt_cbfcf = 0\n",
    "for i in xrange(nfolds):\n",
    "    Umatrix = df_trains[i].values[:,1:]\n",
    "    cfitembased = CF_itembased(Umatrix)\n",
    "    cfslopeone = SlopeOne(Umatrix)\n",
    "    cbfcf = Hybrid_cbf_cf(movies,movieslist,Umatrix)\n",
    "    print 'fold:',i+1\n",
    "    vec_vals = vals_vecs_folds[i]\n",
    "    vec_tests = tests_vecs_folds[i]\n",
    "    for j in xrange(len(vec_vals)):\n",
    "        u_vals = vec_vals[j]\n",
    "        u_test = vec_tests[j]\n",
    "        #cbfcf\n",
    "        u_preds = cbfcf.CalcRatings(u_test,5)\n",
    "        e,c =  SE(u_preds,u_vals)\n",
    "        err_cbfcf +=e\n",
    "        cnt_cbfcf +=c\n",
    "        #cf_userbased\n",
    "        u_preds = CF_userbased(u_test,5,Umatrix)\n",
    "        e,c =  SE(u_preds,u_vals)\n",
    "        err_userbased +=e\n",
    "        cnt_userbased +=c\n",
    "        #cf_itembased\n",
    "        u_preds = cfitembased.CalcRatings(u_test,5)\n",
    "        e,c =  SE(u_preds,u_vals)\n",
    "        err_itembased +=e\n",
    "        cnt_itembased +=c\n",
    "        #slope one\n",
    "        u_preds = cfslopeone.CalcRatings(u_test,5)\n",
    "        e,c =  SE(u_preds,u_vals)\n",
    "        err_slopeone +=e\n",
    "        cnt_slopeone +=c\n",
    "rmse_userbased = np.sqrt(err_userbased/float(cnt_userbased))\n",
    "rmse_itembased = np.sqrt(err_itembased/float(cnt_itembased))\n",
    "rmse_slopeone = np.sqrt(err_slopeone/float(cnt_slopeone))\n",
    "print 'user_userbased rmse:',rmse_userbased,'--',cnt_userbased\n",
    "print 'user_itembased rmse:',rmse_itembased,'--',cnt_itembased\n",
    "print 'slope one rmse:',rmse_slopeone,'--',cnt_slopeone\n",
    "\n",
    "rmse_cbfcf = np.sqrt(err_cbfcf/float(cnt_cbfcf))\n",
    "print 'cbfcf rmse:',rmse_cbfcf,'---',cnt_cbfcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![table5-1](img/table5-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "it: 0  --  -1\n",
      "it: 1  --  57260.8505699\n",
      "it: 2  --  47929.3409804\n",
      "it: 3  --  44144.4291348\n",
      "it: 4  --  41968.003765\n",
      "it: 5  --  40493.252468\n",
      "it: 6  --  39396.671426\n",
      "it: 7  --  38532.7511847\n",
      "it: 8  --  37825.4882603\n",
      "it: 9  --  37230.7281602\n",
      "it: 10  --  36720.6754199\n",
      "it: 11  --  36276.7051366\n",
      "it: 12  --  35885.7066331\n",
      "it: 13  --  35538.0814244\n",
      "it: 14  --  35226.5774773\n",
      "it: 15  --  34945.5739775\n",
      "it: 16  --  34690.6223712\n",
      "it: 17  --  34458.1402765\n",
      "it: 18  --  34245.2004645\n",
      "it: 19  --  34049.3811689\n",
      "it: 20  --  33868.6572543\n",
      "it: 21  --  33701.3193899\n",
      "it: 22  --  33545.912899\n",
      "it: 23  --  33401.190744\n",
      "it: 24  --  33266.0768611\n",
      "it: 25  --  33139.6372059\n",
      "it: 26  --  33021.0566321\n",
      "it: 27  --  32909.6202422\n",
      "it: 28  --  32804.6982104\n",
      "it: 29  --  32705.7333291\n",
      "it: 30  --  32612.2307158\n",
      "it: 31  --  32523.7492461\n",
      "it: 32  --  32439.8943805\n",
      "it: 33  --  32360.3121225\n",
      "it: 34  --  32284.6839028\n",
      "it: 35  --  32212.7222259\n",
      "it: 36  --  32144.1669492\n",
      "it: 37  --  32078.7820875\n",
      "it: 38  --  32016.353059\n",
      "it: 39  --  31956.6843012\n",
      "it: 40  --  31899.597201\n",
      "it: 41  --  31844.9282906\n",
      "it: 42  --  31792.5276695\n",
      "it: 43  --  31742.2576218\n",
      "it: 44  --  31693.9913988\n",
      "it: 45  --  31647.6121456\n",
      "it: 46  --  31603.011952\n",
      "it: 47  --  31560.0910106\n",
      "it: 48  --  31518.7568685\n",
      "it: 49  --  31478.9237611\n",
      "fold: 2\n",
      "it: 0  --  -1\n",
      "it: 1  --  57282.6864201\n",
      "it: 2  --  47889.8611494\n",
      "it: 3  --  44150.0360989\n",
      "it: 4  --  42018.8919985\n",
      "it: 5  --  40579.8246521\n",
      "it: 6  --  39510.5818892\n",
      "it: 7  --  38667.8257454\n",
      "it: 8  --  37977.2516688\n",
      "it: 9  --  37395.9067422\n",
      "it: 10  --  36896.8376779\n",
      "it: 11  --  36462.0162571\n",
      "it: 12  --  36078.7604279\n",
      "it: 13  --  35737.7837177\n",
      "it: 14  --  35432.0640955\n",
      "it: 15  --  35156.1523906\n",
      "it: 16  --  34905.7297191\n",
      "it: 17  --  34677.3128666\n",
      "it: 18  --  34468.0513707\n",
      "it: 19  --  34275.5836036\n",
      "it: 20  --  34097.9320902\n",
      "it: 21  --  33933.4256921\n",
      "it: 22  --  33780.6406645\n",
      "it: 23  --  33638.3552748\n",
      "it: 24  --  33505.5143587\n",
      "it: 25  --  33381.2012909\n",
      "it: 26  --  33264.6155682\n",
      "it: 27  --  33155.0547051\n",
      "it: 28  --  33051.8994795\n",
      "it: 29  --  32954.6018119\n",
      "it: 30  --  32862.6747353\n",
      "it: 31  --  32775.6840384\n",
      "it: 32  --  32693.2412601\n",
      "it: 33  --  32614.9977842\n",
      "it: 34  --  32540.639834\n",
      "it: 35  --  32469.8842093\n",
      "it: 36  --  32402.4746397\n",
      "it: 37  --  32338.17865\n",
      "it: 38  --  32276.7848567\n",
      "it: 39  --  32218.1006265\n",
      "it: 40  --  32161.950041\n",
      "it: 41  --  32108.1721218\n",
      "it: 42  --  32056.6192782\n",
      "it: 43  --  32007.1559439\n",
      "it: 44  --  31959.6573783\n",
      "it: 45  --  31914.0086079\n",
      "it: 46  --  31870.1034896\n",
      "it: 47  --  31827.84388\n",
      "it: 48  --  31787.1388969\n",
      "it: 49  --  31747.9042601\n",
      "fold: 3\n",
      "it: 0  --  -1\n",
      "it: 1  --  56048.270442\n",
      "it: 2  --  46841.493063\n",
      "it: 3  --  43148.4056038\n",
      "it: 4  --  41038.0526681\n",
      "it: 5  --  39611.7549949\n",
      "it: 6  --  38550.1931317\n",
      "it: 7  --  37711.4465659\n",
      "it: 8  --  37022.3751043\n",
      "it: 9  --  36440.9226905\n",
      "it: 10  --  35940.7663949\n",
      "it: 11  --  35504.295288\n",
      "it: 12  --  35119.0926984\n",
      "it: 13  --  34776.0356609\n",
      "it: 14  --  34468.1997603\n",
      "it: 15  --  34190.1918656\n",
      "it: 16  --  33937.723437\n",
      "it: 17  --  33707.3260637\n",
      "it: 18  --  33496.1549428\n",
      "it: 19  --  33301.8489352\n",
      "it: 20  --  33122.4283139\n",
      "it: 21  --  32956.2184063\n",
      "it: 22  --  32801.7915\n",
      "it: 23  --  32657.9219343\n",
      "it: 24  --  32523.5509001\n",
      "it: 25  --  32397.7585157\n",
      "it: 26  --  32279.7414374\n",
      "it: 27  --  32168.7947372\n",
      "it: 28  --  32064.2971092\n",
      "it: 29  --  31965.698701\n",
      "it: 30  --  31872.5110337\n",
      "it: 31  --  31784.298598\n",
      "it: 32  --  31700.6718068\n",
      "it: 33  --  31621.2810531\n",
      "it: 34  --  31545.8116739\n",
      "it: 35  --  31473.9796612\n",
      "it: 36  --  31405.5279941\n",
      "it: 37  --  31340.223488\n",
      "it: 38  --  31277.8540776\n",
      "it: 39  --  31218.2264652\n",
      "it: 40  --  31161.1640778\n",
      "it: 41  --  31106.505287\n",
      "it: 42  --  31054.1018518\n",
      "it: 43  --  31003.8175539\n",
      "it: 44  --  30955.5269965\n",
      "it: 45  --  30909.1145457\n",
      "it: 46  --  30864.4733934\n",
      "it: 47  --  30821.5047271\n",
      "it: 48  --  30780.1169919\n",
      "it: 49  --  30740.2252331\n",
      "fold: 4\n",
      "it: 0  --  -1\n",
      "it: 1  --  56526.7017686\n",
      "it: 2  --  47025.7227619\n",
      "it: 3  --  43244.0236798\n",
      "it: 4  --  41093.9118124\n",
      "it: 5  --  39644.0424226\n",
      "it: 6  --  38566.6610984\n",
      "it: 7  --  37716.6142915\n",
      "it: 8  --  37019.1170738\n",
      "it: 9  --  36431.1494593\n",
      "it: 10  --  35925.7861318\n",
      "it: 11  --  35485.0282649\n",
      "it: 12  --  35096.2054816\n",
      "it: 13  --  34750.027072\n",
      "it: 14  --  34439.4564381\n",
      "it: 15  --  34159.0242593\n",
      "it: 16  --  33904.389118\n",
      "it: 17  --  33672.0448235\n",
      "it: 18  --  33459.1185905\n",
      "it: 19  --  33263.2276932\n",
      "it: 20  --  33082.3750441\n",
      "it: 21  --  32914.8714583\n",
      "it: 22  --  32759.276692\n",
      "it: 23  --  32614.3539866\n",
      "it: 24  --  32479.0345273\n",
      "it: 25  --  32352.3893022\n",
      "it: 26  --  32233.6065752\n",
      "it: 27  --  32121.973673\n",
      "it: 28  --  32016.8621296\n",
      "it: 29  --  31917.7154721\n",
      "it: 30  --  31824.0391041\n",
      "it: 31  --  31735.3918712\n",
      "it: 32  --  31651.378986\n",
      "it: 33  --  31571.6460592\n",
      "it: 34  --  31495.8740381\n",
      "it: 35  --  31423.7748931\n",
      "it: 36  --  31355.0879259\n",
      "it: 37  --  31289.5765951\n",
      "it: 38  --  31227.0257769\n",
      "it: 39  --  31167.2393916\n",
      "it: 40  --  31110.0383399\n",
      "it: 41  --  31055.258703\n",
      "it: 42  --  31002.7501672\n",
      "it: 43  --  30952.3746408\n",
      "it: 44  --  30904.0050374\n",
      "it: 45  --  30857.5242009\n",
      "it: 46  --  30812.8239546\n",
      "it: 47  --  30769.8042576\n",
      "it: 48  --  30728.372454\n",
      "it: 49  --  30688.4426048\n",
      "fold: 5\n",
      "it: 0  --  -1\n",
      "it: 1  --  56944.3511544\n",
      "it: 2  --  47571.7089252\n",
      "it: 3  --  43802.2338486\n",
      "it: 4  --  41648.6918128\n",
      "it: 5  --  40196.538329\n",
      "it: 6  --  39118.9054479\n",
      "it: 7  --  38269.9659178\n",
      "it: 8  --  37574.4232644\n",
      "it: 9  --  36988.9511654\n",
      "it: 10  --  36486.4361712\n",
      "it: 11  --  36048.7557142\n",
      "it: 12  --  35663.1533814\n",
      "it: 13  --  35320.2767513\n",
      "it: 14  --  35013.044425\n",
      "it: 15  --  34735.9545419\n",
      "it: 16  --  34484.6421895\n",
      "it: 17  --  34255.5843788\n",
      "it: 18  --  34045.8964711\n",
      "it: 19  --  33853.1875216\n",
      "it: 20  --  33675.4548817\n",
      "it: 21  --  33511.0057422\n",
      "it: 22  --  33358.3976416\n",
      "it: 23  --  33216.392625\n",
      "it: 24  --  33083.9214203\n",
      "it: 25  --  32960.0550951\n",
      "it: 26  --  32843.9823812\n",
      "it: 27  --  32734.9913554\n",
      "it: 28  --  32632.4545057\n",
      "it: 29  --  32535.8164602\n",
      "it: 30  --  32444.5838289\n",
      "it: 31  --  32358.3167381\n",
      "it: 32  --  32276.6217317\n",
      "it: 33  --  32199.1457852\n",
      "it: 34  --  32125.5712305\n",
      "it: 35  --  32055.6114322\n",
      "it: 36  --  31989.0070874\n",
      "it: 37  --  31925.5230453\n",
      "it: 38  --  31864.9455625\n",
      "it: 39  --  31807.0799256\n",
      "it: 40  --  31751.7483846\n",
      "it: 41  --  31698.78835\n",
      "it: 42  --  31648.0508157\n",
      "it: 43  --  31599.3989743\n",
      "it: 44  --  31552.7069989\n",
      "it: 45  --  31507.8589675\n",
      "it: 46  --  31464.747911\n",
      "it: 47  --  31423.2749697\n",
      "it: 48  --  31383.3486418\n",
      "it: 49  --  31344.884115\n",
      "svd_em rmse: 0.0 -- 1\n",
      "als rmse: 0.0 -- 1\n"
     ]
    }
   ],
   "source": [
    "err_svd = 0.          \n",
    "cnt_svd = 0\n",
    "err_svd_em = 0.\n",
    "cnt_svd_em = 0\n",
    "err_als = 0.\n",
    "cnt_als = 0\n",
    "err_cbfreg = 0.\n",
    "cnt_cbfreg = 0\n",
    "for i in xrange(nfolds):\n",
    "    Umatrix = df_trains[i].values[:,1:]\n",
    "    print 'fold:',i+1\n",
    "    teststartindx = len(Umatrix)\n",
    "    vals_vecs = vals_vecs_folds[i]\n",
    "    tests_vecs = tests_vecs_folds[i]\n",
    "    for k in xrange(len(vals_vecs)):\n",
    "        u_vals = vals_vecs[k]\n",
    "        u_test = tests_vecs[k]\n",
    "        #add test vector to utility matrix\n",
    "        Umatrix = np.vstack([Umatrix,u_test])\n",
    "    \n",
    "    #svd_em_matrix = Hybrid_svd(movies,movieslist,Umatrix,20,'useraverage').matrix#SVD_EM(Umatrix,20,'useraverage',1)\n",
    "    svd_matrix = SVD(Umatrix,20,'itemaverage')\n",
    "    cbf_reg = CBF_regression(movies,Umatrix)\n",
    "    #als_umatrix = SGD(Umatrix,20,50)#ALS(Umatrix,20,50)#NMF_alg(Umatrix,20,'itemaverage',0.001)\n",
    "    #evaluate errors\n",
    "    for indx in xrange(len(vals_vecs)):\n",
    "        #e,c =  SE(als_umatrix[teststartindx+indx],vals_vecs[indx])\n",
    "        #err_als += e\n",
    "        #cnt_als += c\n",
    "        u_preds = cbf_reg.CalcRatings(Umatrix[teststartindx+indx])\n",
    "        e,c = SE(u_preds,vals_vecs[indx])\n",
    "        err_cbfreg +=e\n",
    "        cnt_cbfreg +=c\n",
    "\n",
    "        e,c = SE(svd_matrix[teststartindx+indx],vals_vecs[indx])\n",
    "        err_svd +=e\n",
    "        cnt_svd +=c\n",
    "        #e,c = SE(svd_em_matrix[teststartindx+indx],vals_vecs[indx])\n",
    "        #err_svd_em +=e\n",
    "        #cnt_svd_em +=c\n",
    "\n",
    "if cnt_svd==0: cnt_svd=1\n",
    "if cnt_svd_em==0: cnt_svd_em=1\n",
    "if cnt_als==0: cnt_als=1\n",
    "if cnt_cbfreg==0: cnt_cbfreg=1\n",
    "\n",
    "rmse_als = np.sqrt(err_als/float(cnt_als))\n",
    "rmse_svd = np.sqrt(err_svd/float(cnt_svd))\n",
    "rmse_svd_em = np.sqrt(err_svd_em/float(cnt_svd_em))\n",
    "rmse_cbfreg = np.sqrt(err_cbfreg/float(cnt_cbfreg))\n",
    "\n",
    "print 'svd rmse:',rmse_svd,'--',cnt_svd\n",
    "#print 'svd_em rmse:',rmse_svd_em,'--',cnt_svd_em\n",
    "#print 'als rmse:',rmse_als,'--',cnt_als\n",
    "print 'cbfreg rmse:',rmse_cbfreg,'--',cnt_cbfreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![table5-2](img/table5-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#user_userbased rmse: 1.01381431911 -- 39972\n",
    "#user_itembased rmse: 1.0301785707 -- 39972\n",
    "#slope one rmse: 1.07792084094 -- 39972\n",
    "#cbfcf rmse: 1.0134317593 --- 39972\n",
    "#svd rmse: 1.0145666769 -- 39972\n",
    "#cbfreg rmse: 1.09495415915 -- 39972\n",
    "#NMF_alg rmse: 0.972259334147 -- 39972\n",
    "#SVD EM rmse: 1.03845070461 -- 39972\n",
    "#HYBRID SVD rmse: 1.01385133337 -- 39972\n",
    "#ALS rmse: 2.58784908254 -- 39972\n",
    "#SGD rmse: 1.35396020834 -- 39972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClassificationMetrics(vec_vals,vec_recs,likethreshold=3,shortlist=50,ratingsval=False,vec_test=None):\n",
    "    #convert vals in indxs vec\n",
    "    indxs_like = [i for i in xrange(len(vec_vals)) if vec_vals[i]>likethreshold]\n",
    "    indxs_dislike = [i for i in xrange(len(vec_vals)) if vec_vals[i]<=likethreshold and vec_vals[i]>0]\n",
    "    cnt = len(indxs_like)+len(indxs_dislike)\n",
    "    indxs_rec = []\n",
    "    if ratingsval:\n",
    "        #convert ratings into items's list\n",
    "        if vec_test==None:\n",
    "            raise 'Error no test vector'\n",
    "        indxs_rec = [i for i in xrange(len(vec_recs)) if vec_recs[i]>likethreshold and vec_test[i]<1][:shortlist]\n",
    "    else:\n",
    "        #consider only the first slot of recs\n",
    "        indxs_rec = vec_recs[:shortlist]\n",
    "\n",
    "    tp = len(set(indxs_rec).intersection(set(indxs_like)))\n",
    "    fp = len(set(indxs_rec).intersection(set(indxs_dislike)))\n",
    "    fn = len(set(indxs_like)^(set(indxs_rec).intersection(set(indxs_like))))\n",
    "    precision = 0.\n",
    "    if tp+fp>0:\n",
    "        precision = float(tp)/(tp+fp)\n",
    "    recall = 0.\n",
    "    if tp+fn>0:\n",
    "        recall = float(tp)/(tp+fn)\n",
    "    f1 = 0.\n",
    "    if recall+precision >0:\n",
    "        f1 = 2.*precision*recall/(precision+recall)\n",
    "    \n",
    "    return np.array([precision,recall,f1]),cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![table5-3](img/table5-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "[ 0.56651331  0.16081154  0.23628727]\n",
      "fold: 2\n",
      "[ 0.59850305  0.18860111  0.27172641]\n",
      "fold: 3\n",
      "[ 0.60989212  0.18333456  0.26413943]\n",
      "fold: 4\n",
      "[ 0.60932924  0.19346904  0.27782071]\n",
      "fold: 5\n",
      "[ 0.59372861  0.17254562  0.25126217]\n",
      "precision: 0.595593265581  recall: 0.179752374596  f1: 0.260247197345 --- 39786.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:10: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "tot_measures = np.zeros(3)    \n",
    "cnt_vals = 0.\n",
    "#CF memory based\n",
    "for i in xrange(nfolds):\n",
    "    Umatrix = df_trains[i].values[:,1:]\n",
    "    #cfitembased = CF_itembased(Umatrix)\n",
    "    #cfslopeone = SlopeOne(Umatrix)\n",
    "    #cbfcf = Hybrid_cbf_cf(movies,movieslist,Umatrix)\n",
    "    print 'fold:',i+1\n",
    "    tot_measures_fold = np.zeros(3)\n",
    "    vals_vecs = vals_vecs_folds[i]\n",
    "    tests_vecs = tests_vecs_folds[i]\n",
    "    for j in xrange(len(vals_vecs)):\n",
    "        u_vals = vals_vecs[j]\n",
    "        u_test = tests_vecs[j]\n",
    "        u_preds = CF_userbased(u_test,20,Umatrix)#cfslopeone.CalcRatings(u_test,5)#cfitembased.CalcRatings(u_test,5)#cbfcf.CalcRatings(u_test,20)\n",
    "        tmp_measures,cnt_tmp = ClassificationMetrics(u_vals,u_preds,3,50,True,u_test)\n",
    "        tot_measures_fold +=  tmp_measures\n",
    "        cnt_vals += cnt_tmp\n",
    "    tot_measures_fold /= float(len(vals_vecs))\n",
    "    print tot_measures_fold\n",
    "    tot_measures += tot_measures_fold\n",
    "tot_measures /= float(nfolds)\n",
    "    \n",
    "print 'precision:',tot_measures[0],' recall:',tot_measures[1],' f1:',tot_measures[2],'---',cnt_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CF_userbased precision: 0.595593265581  recall: 0.179752374596  f1: 0.260247197345 --- 39786.0\n",
    "#CF_itembased precision: 0.573049057653  recall: 0.150154902908  f1: 0.224407731332 --- 39786.0\n",
    "#SlopeOne precision: 0.572945843878  recall: 0.166998383035  f1: 0.24433916059 --- 39786.0\n",
    "#Hybrid_cbf_cf precision: 0.600636639987  recall: 0.183293616752  f1: 0.26385405692 --- 39786.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "[ 0.64264754  0.29272826  0.37885232]\n",
      "fold: 2\n",
      "[ 0.64008348  0.32754908  0.40919527]\n",
      "fold: 3\n",
      "[ 0.69438685  0.30352264  0.4023821 ]\n",
      "fold: 4\n",
      "[ 0.71752179  0.30733163  0.40810444]\n",
      "fold: 5\n",
      "[ 0.70219096  0.3342881   0.42251521]\n",
      "precision: 0.679366124465  recall: 0.313083943066  f1: 0.404209869025 --- 39786.0\n"
     ]
    }
   ],
   "source": [
    "#CF model based\n",
    "cnt_vals=0.\n",
    "tot_measures = np.zeros(3)\n",
    "for i in xrange(nfolds):\n",
    "    Umatrix = df_trains[i].values[:,1:]\n",
    "    print 'fold:',i+1\n",
    "    teststartindx = len(Umatrix)\n",
    "    \n",
    "    vals_vecs = vals_vecs_folds[i]\n",
    "    tests_vecs = tests_vecs_folds[i]\n",
    "    for k in xrange(len(vals_vecs)):\n",
    "        u_vals = vals_vecs[k]\n",
    "        u_test = tests_vecs[k]\n",
    "        #add test vector to utility matrix\n",
    "        Umatrix = np.vstack([Umatrix,u_test])\n",
    "    \n",
    "    #svd_matrix = SVD_EM(Umatrix,20,'useraverage',30)#SVD(Umatrix,20,'itemaverage') #Hybrid_svd(movies,movieslist,Umatrix,20,'useraverage').matrix#SGD(Umatrix,20,50)#ALS(Umatrix,20,50) \n",
    "    #matrix=NMF_alg(Umatrix,20,'useraverage')\n",
    "    #cbf_reg = CBF_regression(movies,Umatrix)\n",
    "    #cbf_av = CBF_averageprofile(movies,movieslist)\n",
    "    #llr = LogLikelihood(Umatrix,movieslist)\n",
    "    assrules = AssociationRules(Umatrix,movieslist)\n",
    "    \n",
    "    tot_measures_fold = np.zeros(3)\n",
    "    for indx in xrange(len(vals_vecs)):\n",
    "        #u_preds = cbf_reg.CalcRatings(Umatrix[teststartindx+indx])#cbf_av.GetRecMovies(Umatrix[teststartindx+indx],True)\n",
    "        #u_preds = svd_matrix[teststartindx+indx]#matrix[teststartindx+indx] \n",
    "        u_preds = assrules.GetRecItems(Umatrix[teststartindx+indx],True)#llr.GetRecItems(Umatrix[teststartindx+indx],True)\n",
    "        tmp_measures,cnt_tmp = ClassificationMetrics(vals_vecs[indx],u_preds,3,50,False,Umatrix[teststartindx+indx])\n",
    "        tot_measures_fold +=  tmp_measures\n",
    "        cnt_vals += cnt_tmp\n",
    "    tot_measures_fold = tot_measures_fold/float(len(vals_vecs))\n",
    "    print tot_measures_fold\n",
    "    tot_measures += tot_measures_fold\n",
    "tot_measures = tot_measures/float(nfolds)\n",
    "print 'precision:',tot_measures[0],' recall:',tot_measures[1],' f1:',tot_measures[2],'---',cnt_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![table5-4](img/table5-4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#llr precision: 0.632059422601  recall: 0.306911656684  f1: 0.389728618382 --- 39786.0\n",
    "#Hybrid_svd precision: 0.540616355878  recall: 0.122568676777  f1: 0.188867837509 --- 39786.0\n",
    "#als precision: 0.574768962349  recall: 0.154765744996  f1: 0.232415857722 --- 39786.0\n",
    "#sgd precision: 0.522492554867  recall: 0.116681592379  f1: 0.182113478188 --- 39786.0\n",
    "#SVD precision: 0.531278228807  recall: 0.119701346615  f1: 0.184269894611 --- 39786.0\n",
    "#SVD-EM precision: 0.576567716327  recall: 0.159558142114  f1: 0.236321594653 --- 39786.0\n",
    "#NMF_alg precision: 0.532487775416  recall: 0.125034210484  f1: 0.191971985488 --- 39786.0\n",
    "#CBF_regression precision: 0.536374177877  recall: 0.128159010191  f1: 0.196055670058 --- 39786.0\n",
    "#CBF_averageprofile precision: 0.561491582647  recall: 0.118988755524  f1: 0.185138199893 --- 39786.0\n",
    "#AssociationRules precision: 0.679366124465  recall: 0.313083943066  f1: 0.404209869025 --- 39786.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
